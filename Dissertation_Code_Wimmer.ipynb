{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5422a4b-5b33-4658-9dfa-065196b8485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "# packages for data preparation and plotting\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import table\n",
    "import holidays\n",
    "import cftime\n",
    "from netCDF4 import Dataset\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# packages for modeling and evaluation\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "# other\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eda859-26b6-4c08-a954-0f3788d4aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ded8c1-610b-457a-98c4-9a6986c57fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, inspect and clean the flight delay dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e915df4-14a5-4b62-88f3-c43dd03403da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and combining the flight data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "flight_data = pd.DataFrame()\n",
    "\n",
    "data_folder = \"./flight_data\"\n",
    "csv_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(data_folder, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    flight_data = flight_data.append(df, ignore_index=True)\n",
    "\n",
    "flight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc78b0-2b87-4bf2-8bc6-cf7f74ddc2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for JFK airport\n",
    "\n",
    "df_1 = flight_data[flight_data['ORIGIN'] == 'JFK']\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be099434-0d11-4b9e-bd0e-43a00b957aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by date\n",
    "\n",
    "df_1['FL_DATE'] = pd.to_datetime(df_1['FL_DATE'])\n",
    "\n",
    "df_1 = df_1.sort_values(by='FL_DATE')\n",
    "\n",
    "df_1 = df_1.reset_index(drop=True)\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c030f0c-645f-4dff-a0da-a1640deaf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the data\n",
    "# Inspecting null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3e975-20eb-475d-a55a-fe58eb81e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8011331-3a45-4fa0-a57a-3328dd5b88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_rows = df_1[df_1['AIR_TIME'].isnull()]\n",
    "\n",
    "# Display the rows with missing values in 'arr_flights'\n",
    "print(missing_values_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfad5e2-2e60-47b8-92f6-7422be2f2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.dropna(subset=['AIR_TIME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10699881-724f-4e62-8b2b-9efb2a0be69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values in a column with 0\n",
    "df_1['DEP_DELAY_NEW'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f9e04-7e97-4e73-aa24-58bd59342956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace NaN values in a column with 0\n",
    "df_1['WEATHER_DELAY'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a5dbf-35a6-4191-a0e6-a30eb6ea9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values in a column with 0\n",
    "df_1['NAS_DELAY'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0e25f-1438-4006-a07b-9044326a55b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e276f-2304-4b9f-b720-1d004f8f00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca2eac-b070-46e6-8ca0-b37a8b1cb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d5733-52ec-47eb-8118-0a7dbe1e4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary variable Delayed. Is 0 if on-time and is 1 if delayed.\n",
    "\n",
    "df_1['Delayed'] = np.where((df_1['DEP_DELAY_NEW'] > 0) | (df_1['CANCELLED'] > 0), 1, 0)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a13bce-7338-40be-be83-704648881681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary variable Weather_Delayed. Is 0 if on-time and is 1 if delayed because of weather.\n",
    "\n",
    "df_1['Weather_Delayed'] = np.where((df_1['WEATHER_DELAY'] > 0) | (df_1['NAS_DELAY'] > 0), 1, 0)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf02ac8-81ba-4cee-b826-cfa65393d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to classify whether the date is a weekday or weekend\n",
    "\n",
    "# Create a custom function to classify the days\n",
    "def classify_day_type(date):\n",
    "    if date.weekday() < 5:  # 0-4 correspond to Monday to Friday\n",
    "        return 'weekday'\n",
    "    else:\n",
    "        return 'weekend'\n",
    "\n",
    "# Apply the function to create the \"Day_Type\" column\n",
    "df_1['Day_Type'] = df_1['FL_DATE'].apply(classify_day_type)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cffdde-18cc-4b40-b830-6b115d791841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8389d40-b332-408e-a0f8-cab2757593c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fdbead-5f18-4fc6-a4b6-62fa05b9d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, inspect and clean the ERA5 climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5290790-0fcb-477f-8b40-0a2677693f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefef56b-93c7-4bcf-be61-5eed74d89d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "wind_ds = nc.Dataset('./ERA5_data/ERA5_10mwindgust.nc', 'r')\n",
    "wind_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16d4a6-8957-426a-a44e-040eb90e0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dimname, dimobj in wind_ds.dimensions.items():\n",
    "    print(f\"{dimname}: {len(dimobj)}\")\n",
    "\n",
    "# List variables\n",
    "print(\"\\nVariables:\")\n",
    "for varname, varobj in wind_ds.variables.items():\n",
    "    print(f\"{varname}: {varobj.shape} - {varobj.dtype}\")\n",
    "\n",
    "# List global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attrname in wind_ds.ncattrs():\n",
    "    print(f\"{attrname}: {getattr(wind_ds, attrname)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2536ba-8c35-4085-a117-c2755f3bba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "wind_ds = nc.Dataset('./ERA5_data/ERA5_10mwindgust.nc', 'r')\n",
    "\n",
    "# Extract time and wind gust values\n",
    "time_values = wind_ds.variables['time'][:]\n",
    "wind_gust_values = wind_ds.variables['fg10'][:, :, 0, 0]\n",
    "\n",
    "# Filter data until August 31, 2023\n",
    "end_date = pd.to_datetime(\"2023-08-31\")\n",
    "filtered_indices = time_values <= pd.Timestamp(end_date).timestamp()\n",
    "\n",
    "# Convert time values to a human-readable format\n",
    "hours = time_values[filtered_indices] % 24\n",
    "dates = pd.to_datetime(time_values[filtered_indices], unit='h', origin='1900-01-01')\n",
    "dates += pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Date': dates, 'Wind Gust': wind_gust_values[filtered_indices, 0]})\n",
    "\n",
    "# Group by date and calculate both the maximum and average wind gust values for each day\n",
    "df_2 = df.groupby(df['Date'].dt.date)['Wind Gust'].agg(['max', 'mean']).reset_index()\n",
    "df_2.columns = ['Date', 'Max Wind Gust', 'Average Wind Gust']\n",
    "\n",
    "# Print the DataFrame with both maximum and average wind gust values per day\n",
    "print(df_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79873b4e-542d-4cd4-8bc1-dc11a6b7f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to a datetime type (if it's not already)\n",
    "df_2['Date'] = pd.to_datetime(df_2['Date'])\n",
    "\n",
    "# Filter the DataFrame to include only rows until 2023-08-31\n",
    "df_2 = df_2[df_2['Date'] <= '2023-08-31']\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfdde93-097c-4698-9784-b86598bbfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'FL_DATE' and 'Date' columns\n",
    "merged_df = df_1.merge(df_2, left_on='FL_DATE', right_on='Date', how='left')\n",
    "\n",
    "# Drop the 'Date' column \n",
    "merged_df = merged_df.drop(columns=['Date'])\n",
    "\n",
    "# Now, merged_df contains the Max Wind Gust and Average Wind Gust columns from df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dccb01-28ff-4190-80a5-d56d7889f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf38221-c605-4e97-80bd-700b8c541d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max total precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2166a2f-4895-4691-a337-997279d0fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "prec_ds = nc.Dataset('./ERA5_data/ERA5_maxtotalprec.nc', 'r')\n",
    "prec_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9844334-e7d4-4eed-b12f-8f07f69003f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dimname, dimobj in prec_ds.dimensions.items():\n",
    "    print(f\"{dimname}: {len(dimobj)}\")\n",
    "\n",
    "# List variables\n",
    "print(\"\\nVariables:\")\n",
    "for varname, varobj in prec_ds.variables.items():\n",
    "    print(f\"{varname}: {varobj.shape} - {varobj.dtype}\")\n",
    "\n",
    "# List global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attrname in prec_ds.ncattrs():\n",
    "    print(f\"{attrname}: {getattr(prec_ds, attrname)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc654ef-30e5-4b80-9357-7f897ad7db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "prec_ds = nc.Dataset('./ERA5_data/ERA5_maxtotalprec.nc', 'r')\n",
    "\n",
    "# Extract time and wind gust values\n",
    "time_values = prec_ds.variables['time'][:]\n",
    "prec_values = prec_ds.variables['mxtpr'][:, :, 0, 0]\n",
    "\n",
    "# Filter data until August 31, 2023\n",
    "end_date = pd.to_datetime(\"2023-08-31\")\n",
    "filtered_indices = time_values <= pd.Timestamp(end_date).timestamp()\n",
    "\n",
    "# Convert time values to a human-readable format (you can adjust this as needed)\n",
    "hours = time_values[filtered_indices] % 24\n",
    "dates = pd.to_datetime(time_values[filtered_indices], unit='h', origin='1900-01-01')\n",
    "dates += pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Create a DataFrame\n",
    "df_3 = pd.DataFrame({'Date': dates, 'Precipitation': prec_values[filtered_indices, 0]})\n",
    "\n",
    "# Group by date and calculate both the maximum and average wind gust values for each day\n",
    "df_3 = df_3.groupby(df_3['Date'].dt.date)['Precipitation'].agg(['max', 'mean']).reset_index()\n",
    "df_3.columns = ['Date', 'Max Precipitation', 'Average Precipitation']\n",
    "\n",
    "# Print the DataFrame with both maximum and average wind gust values per day\n",
    "print(df_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b593e93-6645-4c7f-a72a-16d3a0a1b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to a datetime type (if it's not already)\n",
    "df_3['Date'] = pd.to_datetime(df_3['Date'])\n",
    "\n",
    "# Filter the DataFrame to include only rows until 2023-08-31\n",
    "df_3 = df_3[df_3['Date'] <= '2023-08-31']\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731739c-a495-4403-b7eb-e52cdaee92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'FL_DATE' and 'Date' columns\n",
    "\n",
    "df_3['Date'] = pd.to_datetime(df_3['Date'])\n",
    "merged_df_2 = merged_df.merge(df_3, left_on='FL_DATE', right_on='Date', how='left')\n",
    "\n",
    "# Drop the 'Date' column from the merged dataframe if you don't need it\n",
    "merged_df_2 = merged_df_2.drop(columns=['Date'])\n",
    "\n",
    "# Now, merged_df contains the Max Wind Gust and Average Wind Gust columns from df_2\n",
    "merged_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f8c77-9a7d-461d-aa15-c8908c38ca0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c26292-ac6c-44ae-830f-cc669c5336df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c846b-166c-43a6-856f-58c726f25ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "maxtemp_ds = nc.Dataset('./ERA5_data/ERA5_max2mtemp.nc', 'r')\n",
    "maxtemp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43224d-624f-46ae-994f-7a87daa1c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dimname, dimobj in maxtemp_ds.dimensions.items():\n",
    "    print(f\"{dimname}: {len(dimobj)}\")\n",
    "\n",
    "# List variables\n",
    "print(\"\\nVariables:\")\n",
    "for varname, varobj in maxtemp_ds.variables.items():\n",
    "    print(f\"{varname}: {varobj.shape} - {varobj.dtype}\")\n",
    "\n",
    "# List global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attrname in maxtemp_ds.ncattrs():\n",
    "    print(f\"{attrname}: {getattr(maxtemp_ds, attrname)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df7f59-810f-4e84-9d39-99082c834c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "maxtemp_ds = nc.Dataset('./ERA5_data/ERA5_max2mtemp.nc', 'r')\n",
    "\n",
    "# Extract time and wind gust values\n",
    "time_values = maxtemp_ds.variables['time'][:]\n",
    "maxtemp_values = maxtemp_ds.variables['mx2t'][:, :, 0, 0]\n",
    "\n",
    "# Filter data until August 31, 2023\n",
    "end_date = pd.to_datetime(\"2023-08-31\")\n",
    "filtered_indices = time_values <= pd.Timestamp(end_date).timestamp()\n",
    "\n",
    "# Convert time values to a human-readable format (you can adjust this as needed)\n",
    "hours = time_values[filtered_indices] % 24\n",
    "dates = pd.to_datetime(time_values[filtered_indices], unit='h', origin='1900-01-01')\n",
    "dates += pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Create a DataFrame\n",
    "df_4 = pd.DataFrame({'Date': dates, 'Max Temperature': maxtemp_values[filtered_indices, 0]})\n",
    "\n",
    "# Group by date and calculate both the maximum and average wind gust values for each day\n",
    "df_4 = df_4.groupby(df_4['Date'].dt.date)['Max Temperature'].agg(['max']).reset_index()\n",
    "df_4.columns = ['Date', 'Max Temperature']\n",
    "\n",
    "# Print the DataFrame with both maximum and average wind gust values per day\n",
    "print(df_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da4571-a131-456c-94a6-25949a964ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand where NaN values start\n",
    "first_nan_date = df_4[df_4['Max Temperature'].isna()]['Date'].iloc[0]\n",
    "\n",
    "print(\"The NaN values start from:\", first_nan_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39072e15-76da-4ca4-bc3c-3cab8c4c565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to a datetime type (if it's not already)\n",
    "df_4['Date'] = pd.to_datetime(df_4['Date'])\n",
    "\n",
    "# Filter the DataFrame to include only rows until 2023-08-31\n",
    "df_4 = df_4[df_4['Date'] <= '2023-07-31']\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ff0ac-2c63-47fb-970d-659119c938f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the temperature values to °C\n",
    "df_4['Max Temperature (°C)'] = df_4['Max Temperature'] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823932d-894f-4229-9404-00cba871be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a1952-4bf8-4911-90cd-1302dfc247e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge flight delay and temperature dataframes\n",
    "import pandas as pd\n",
    "\n",
    "merged_df_2['FL_DATE'] = pd.to_datetime(merged_df_2['FL_DATE'])  # Convert the 'FL_DATE' column to a datetime type\n",
    "end_date = pd.to_datetime('2023-07-31')  # Define the end date\n",
    "\n",
    "# Filter the DataFrame to keep only rows up to July 31, 2023\n",
    "merged_df_2 = merged_df_2[merged_df_2['FL_DATE'] <= end_date]\n",
    "merged_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef2661-1bc2-4235-820d-34ffcc9cf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'FL_DATE' and 'Date' columns\n",
    "merged_df_3 = merged_df_2.merge(df_4, left_on='FL_DATE', right_on='Date', how='left')\n",
    "\n",
    "# Drop the 'Date' column from the merged dataframe if you don't need it\n",
    "merged_df_3 = merged_df_3.drop(columns=['Date'])\n",
    "\n",
    "# Now, merged_df contains the Max Wind Gust and Average Wind Gust columns from df_2\n",
    "merged_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88bd29-86f4-4d44-a9ef-4f1da26645bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e8970-087f-464d-b509-bb0393f861db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd0759-cce1-49e4-9215-88d6b09e27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "mintemp_ds = nc.Dataset('./ERA5_data/ERA5_min2mtemp.nc', 'r')\n",
    "mintemp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05dacb8-e969-4225-a477-47de8ac2f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dimname, dimobj in mintemp_ds.dimensions.items():\n",
    "    print(f\"{dimname}: {len(dimobj)}\")\n",
    "\n",
    "# List variables\n",
    "print(\"\\nVariables:\")\n",
    "for varname, varobj in mintemp_ds.variables.items():\n",
    "    print(f\"{varname}: {varobj.shape} - {varobj.dtype}\")\n",
    "\n",
    "# List global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attrname in mintemp_ds.ncattrs():\n",
    "    print(f\"{attrname}: {getattr(mintemp_ds, attrname)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f81459-2d9a-405e-82cc-c92d3638ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "mintemp_ds = nc.Dataset('./ERA5_data/ERA5_min2mtemp.nc', 'r')\n",
    "\n",
    "# Extract time and wind gust values\n",
    "time_values = mintemp_ds.variables['time'][:]\n",
    "mintemp_values = mintemp_ds.variables['mn2t'][:, :, 0, 0]\n",
    "\n",
    "# Filter data until August 31, 2023\n",
    "end_date = pd.to_datetime(\"2023-08-31\")\n",
    "filtered_indices = time_values <= pd.Timestamp(end_date).timestamp()\n",
    "\n",
    "# Convert time values to a human-readable format (you can adjust this as needed)\n",
    "hours = time_values[filtered_indices] % 24\n",
    "dates = pd.to_datetime(time_values[filtered_indices], unit='h', origin='1900-01-01')\n",
    "dates += pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Create a DataFrame\n",
    "df_5 = pd.DataFrame({'Date': dates, 'Min Temperature': mintemp_values[filtered_indices, 0]})\n",
    "\n",
    "# Group by date and calculate both the maximum and average wind gust values for each day\n",
    "df_5 = df_5.groupby(df_5['Date'].dt.date)['Min Temperature'].agg(['min']).reset_index()\n",
    "df_5.columns = ['Date', 'Min Temperature']\n",
    "\n",
    "# Print the DataFrame with both maximum and average wind gust values per day\n",
    "print(df_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9edc7f-0bf3-467c-b0f7-0f4330228517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to a datetime type (if it's not already)\n",
    "df_5['Date'] = pd.to_datetime(df_5['Date'])\n",
    "\n",
    "# Filter the DataFrame to include only rows until 2023-08-31\n",
    "df_5 = df_5[df_5['Date'] <= '2023-07-31']\n",
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b422d-f6bb-4142-a833-818b00f1fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change temeprature values to °C\n",
    "df_5['Min Temperature (°C)'] = df_5['Min Temperature'] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0d16a-8d95-4da2-98f6-4c847e638276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57b5e1-bb9b-459b-ac99-6ae6958f35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'FL_DATE' and 'Date' columns\n",
    "merged_df_4 = merged_df_3.merge(df_5, left_on='FL_DATE', right_on='Date', how='left')\n",
    "\n",
    "# Add a column for weather delay cost\n",
    "merged_df_4['Estimated_Weather_Delay_Cost'] = merged_df_4['WEATHER_DELAY'] * 101.18 + merged_df_4['NAS_DELAY'] * 101.18\n",
    "\n",
    "# create a new dataframe that can be used later on\n",
    "merged_df_5 = merged_df_4\n",
    "\n",
    "# Drop the 'Date' column from the merged dataframe if you don't need it\n",
    "merged_df_4 = merged_df_4.drop(columns=['Date'])\n",
    "\n",
    "# Now, merged_df contains the Max Wind Gust and Average Wind Gust columns from df_2\n",
    "merged_df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426629c-14a1-43f9-b7aa-eb6ba177bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "merged_df_4.drop(columns=['Max Temperature', 'Min Temperature'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19127240-f5b9-4b32-b86f-214b02528661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52e6c6-1456-4c6e-9cf0-1fedeef8ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add delay cost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a6c45-6c61-4e16-b651-7ab50f91f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for delay cost\n",
    "#In 2022, the average cost of aircraft block (taxi plus airborne) time for U.S. passenger airlines was $101.18 per minute\n",
    "\n",
    "merged_df_4['Estimated_Delay_Cost'] = merged_df_4['DEP_DELAY_NEW'] * 101.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b0e46-81a7-46d9-a730-f7680184caf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe82dd-8296-4c81-9134-e2335ca40fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the dataframe for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fc5ae-b546-44fe-9df7-5059e7b8b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the 'FL_DATE' is before 2022\n",
    "merged_df_4 = merged_df_4[merged_df_4['FL_DATE'].dt.year < 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc5752-2cc7-44ba-b37b-84bd6f5e02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column\n",
    "merged_df_4['DOY'] = pd.to_datetime(merged_df_4['FL_DATE']).dt.dayofyear\n",
    "merged_df_4 = merged_df_4.drop(columns=['FL_DATE'])  # Remove the original 'FL_DATE' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff582c91-3bd5-4bd9-a0e1-5b5896c84c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['CANCELLED', 'ORIGIN', 'DEP_DELAY_NEW', 'WEATHER_DELAY', 'NAS_DELAY', 'Delayed', 'Estimated_Delay_Cost', 'Delayed', 'Max Wind Gust','Max Precipitation']\n",
    "merged_df_4 = merged_df_4.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911929d5-142f-4d80-9e35-2a0110e21018",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5ebdc-d5b3-4b9e-b730-f8c17e48d985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb18c3-3335-40c3-ab09-c5fc7c6346d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for inspection of variable relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c93533-b319-4d28-821e-26b75feea756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot percentage of weather delayed flights by carrier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set font to Times New Roman\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# Calculate the percentage of Weather_Delayed being 0 and 1 for each OP_UNIQUE_CARRIER\n",
    "carrier_percentage = merged_df_4.groupby(['OP_UNIQUE_CARRIER', 'Weather_Delayed']).size().unstack(fill_value=0)\n",
    "carrier_percentage['Total'] = carrier_percentage[0] + carrier_percentage[1]\n",
    "carrier_percentage['Percentage_0'] = (carrier_percentage[0] / carrier_percentage['Total']) * 100\n",
    "carrier_percentage['Percentage_1'] = (carrier_percentage[1] / carrier_percentage['Total']) * 100\n",
    "\n",
    "# Plot the percentage bar plots with total adding up to 100%\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='OP_UNIQUE_CARRIER', y='Percentage_0', data=carrier_percentage.reset_index(), color='#1f78b4', label='Weather_Delayed = 0')\n",
    "sns.barplot(x='OP_UNIQUE_CARRIER', y='Percentage_1', data=carrier_percentage.reset_index(), color='#ff7f0e', bottom=carrier_percentage['Percentage_0'], label='Weather_Delayed = 1')\n",
    "plt.xlabel('OP_UNIQUE_CARRIER [-]')\n",
    "plt.ylabel('Percentage [%]')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b026a-c5a8-4458-93ec-9800348bf6b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the relationship of airtime and flight status\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set font to Times New Roman and set font size\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# Create a seaborn boxplot with grey gridlines\n",
    "sns.set(style=\"whitegrid\", rc={\"grid.linewidth\": 0.5, \"grid.color\": \"grey\"})\n",
    "ax = sns.boxplot(x='Weather_Delayed', y='AIR_TIME', data=merged_df_4, showfliers=False)\n",
    "\n",
    "# Add vertical gridlines\n",
    "ax.set(xticks=range(len(merged_df_4['Weather_Delayed'].unique())))\n",
    "ax.xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Weather_Delayed [-]')\n",
    "ax.set_ylabel('AIR_TIME [Minutes]')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700a8ef-c69e-43bd-882e-e3c21fdd3bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationships of weather variables and flight status\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the font to Times New Roman\n",
    "rcParams['font.family'] = 'times new roman'\n",
    "rcParams['font.size'] = 12\n",
    "\n",
    "# Filter the DataFrame to include only the relevant columns for boxplots\n",
    "relevant_columns = [\n",
    "    \"Average Wind Gust\",\n",
    "    \"Average Precipitation\",\n",
    "    \"Max Temperature (°C)\",\n",
    "    \"Min Temperature (°C)\"\n",
    "]\n",
    "\n",
    "# Create subplots for boxplots without outliers\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(relevant_columns):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    sns.boxplot(x=merged_df_4[\"Weather_Delayed\"], y=merged_df_4[column], showfliers=False)\n",
    "\n",
    "    # Set the x-axis and y-axis labels with Times New Roman font\n",
    "    unit_label = \"[°C]\" if \"Temperature\" in column else \"[m s-1]\" if \"Wind Gust\" in column else \"[kg m-2 s-1]\"\n",
    "    plt.xlabel(\"Weather Delayed [-]\", fontdict={'family': 'times new roman', 'size': 12})\n",
    "    plt.ylabel(f\"{column.replace(' (°C)', '')} {unit_label}\",\n",
    "               fontdict={'family': 'times new roman', 'size': 12})\n",
    "\n",
    "    # Add gray gridlines that are not dotted\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=0.25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66643187-da8c-49a4-acfc-03d71677c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the minimum and maximum values of the weather variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b58ee0-cb5a-4dd8-b848-f8f2552e415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Average Wind Gust'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e01f4e-c498-487c-ba77-0283aec8a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Average Wind Gust'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6d6cc-26be-4bb9-bce4-ce9f53d661b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Min Temperature (°C)'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d66f2-0aae-4e78-b1f9-e90e2e05770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Min Temperature (°C)'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a3983-fc8d-4d03-9cfa-013c7c1ec7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Max Temperature (°C)'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410fa6da-75fd-4986-be03-e48779f4b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Max Temperature (°C)'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d1bf0-6b7f-4b73-9617-b37d6e8f7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Average Precipitation'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e6cdd-04f7-480d-8278-e77b50db744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_4['Average Precipitation'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168613bf-b1ae-42db-96db-ede9604d7f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1907113-75e8-4fb5-97f6-11565b1e2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the balance of flights that are delayed vs on-time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the font to Times New Roman\n",
    "rcParams['font.family'] = 'times new roman'\n",
    "\n",
    "# Filter the DataFrame to include only the relevant columns for histograms\n",
    "relevant_columns = [\"Weather_Delayed\"]\n",
    "\n",
    "# Create subplots for histograms\n",
    "plt.figure(figsize=(12, 8), facecolor='white')  # Set the background color to white\n",
    "\n",
    "for i, column in enumerate(relevant_columns):\n",
    "    ax = plt.subplot(3, 4, i+1)\n",
    "    \n",
    "    # Extract the data as a numpy array\n",
    "    data = merged_df_4[column].values\n",
    "    \n",
    "    # Separate the data based on outcomes\n",
    "    delayed_data = data[data == 0]\n",
    "    on_time_data = data[data == 1]\n",
    "    \n",
    "    # Set everything to dark blue\n",
    "    delayed_color = 'darkblue'\n",
    "    on_time_color = 'darkorange'\n",
    "    \n",
    "    # Plot separate histograms for each outcome\n",
    "    plt.hist(delayed_data, bins=[-0.25, 0.25, 0.75, 1.25], color=delayed_color, alpha=0.7, label='Outcome 0')\n",
    "    plt.hist(on_time_data, bins=[-0.25, 0.25, 0.75, 1.25], color=on_time_color, alpha=0.7, label='Outcome 1')\n",
    "    \n",
    "    # Set the frame (spines) to black and make them thinner\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)  # Adjust the line width for the frame\n",
    "    \n",
    "    # Set the x-axis and y-axis labels\n",
    "    ax.set_xlabel(\"Weather_Delayed [-]\", color='black', fontdict={'fontsize': 12})  # Set the x-axis label and color\n",
    "    ax.set_ylabel(\"Frequency [-]\", color='black', fontdict={'fontsize': 12})  # Set the y-axis label and color\n",
    "\n",
    "    # Set x-axis ticks to only 0 and 1\n",
    "    ax.set_xticks([0, 1])  \n",
    "    ax.set_xticklabels([0, 1])  # Set the x-axis tick labels\n",
    "    \n",
    "    \n",
    "    # Set gridlines to be in the background, grey, and not dotted\n",
    "    ax.set_axisbelow(True)\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure as a picture (e.g., histogram.png)\n",
    "plt.savefig(\"histogram.png\", facecolor='white')  # Set the background color when saving\n",
    "\n",
    "# Display the figure (optional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4be05-ce51-48ce-b8f5-7daf34a0b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_df_4[\"Weather_Delayed\"] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997050bb-f80c-44e8-b68a-d69ca3511a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_df_4[\"Weather_Delayed\"] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c0c96-8269-45ed-8409-493ccaff122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation of variables\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the font to Times New Roman\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = merged_df_4.corr()\n",
    "\n",
    "# Create a heatmap with non-overlapping annotations and a title\n",
    "plt.figure(figsize=(8, 6))  # Reduce the figure size\n",
    "\n",
    "# Set the annot parameter to display values in each cell\n",
    "# Use a diverging color map with red for positive values, blue for negative values, and center at 0 (white)\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm_r', center=0, annot_kws={\"size\": 10})\n",
    "\n",
    "# Save the plot as a picture with higher resolution (e.g., correlation_matrix.png)\n",
    "plt.savefig(\"correlation_matrix.png\", dpi=50)  # Adjust the DPI as needed\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd909ad1-2c7e-43bb-ae69-5e3efc5c337f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f5ab5-6923-4ca3-bb82-fb28ad219014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48294fdf-6c2c-4694-94eb-3f5f9039fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fb7ed-c1fb-4cb0-a513-3dce1a26229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51b050-82af-4586-99fe-bb83cc272048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for modeling\n",
    "\n",
    "# Select input features and target variable\n",
    "selected_features = [\n",
    "    'DOY', 'OP_UNIQUE_CARRIER', 'CRS_DEP_TIME', 'AIR_TIME', 'Day_Type',\n",
    "    'Average Wind Gust', 'Average Precipitation', 'Min Temperature (°C)'\n",
    "]\n",
    "X = merged_df_4[selected_features]\n",
    "y = merged_df_4['Weather_Delayed']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = ['CRS_DEP_TIME', 'AIR_TIME', 'Average Wind Gust', 'Average Precipitation', 'Min Temperature (°C)', 'DOY']\n",
    "categorical_cols = ['OP_UNIQUE_CARRIER', 'Day_Type']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Handle categorical features with one-hot encoding\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "feature_names = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "X_encoded = pd.DataFrame(X_encoded, columns=feature_names)\n",
    "X = pd.concat([X.drop(columns=categorical_cols), X_encoded], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ff8bf-1329-42cc-b68e-d272657af704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbabb89-f59d-48e1-8ded-1322452763ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1108d9e-52c4-4165-a702-76491cd01c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address class imbalance using RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.6, random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Create new interaction terms for the training set\n",
    "for carrier in ['AA', 'AS', 'B6', 'DL', 'EV', 'HA', 'MQ', 'OH', 'OO', 'UA', 'US', 'VX', 'YX']:\n",
    "    X_train_resampled[f'OP_CARRIER_DEP_TIME_Interact_{carrier}'] = X_train_resampled[f'OP_UNIQUE_CARRIER_{carrier}'] * X_train_resampled['CRS_DEP_TIME']\n",
    "    X_train_resampled[f'OP_CARRIER_AIR_TIME_Interact_{carrier}'] = X_train_resampled[f'OP_UNIQUE_CARRIER_{carrier}'] * X_train_resampled['AIR_TIME']\n",
    "\n",
    "# Create new interaction terms for the test set\n",
    "for carrier in ['AA', 'AS', 'B6', 'DL', 'EV', 'HA', 'MQ', 'OH', 'OO', 'UA', 'US', 'VX', 'YX']:\n",
    "    X_test[f'OP_CARRIER_DEP_TIME_Interact_{carrier}'] = X_test[f'OP_UNIQUE_CARRIER_{carrier}'] * X_test['CRS_DEP_TIME']\n",
    "    X_test[f'OP_CARRIER_AIR_TIME_Interact_{carrier}'] = X_test[f'OP_UNIQUE_CARRIER_{carrier}'] * X_test['AIR_TIME']\n",
    "\n",
    "\n",
    "# Model \n",
    "\n",
    "# Define fixed hyperparameters for the logistic regression model\n",
    "logistic_params = {\n",
    "     'C': 1000,  # Regularization parameter\n",
    "    'max_iter': 500  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Initialize the logistic regression model with fixed hyperparameters\n",
    "model = LogisticRegression(**logistic_params)\n",
    "\n",
    "# Define StratifiedKFold with 3 folds\n",
    "stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation results for each fold\n",
    "accuracies = []\n",
    "class_reports = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_idx, test_idx in stratified_cv.split(X_train_resampled, y_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_resampled.iloc[train_idx], X_train_resampled.iloc[test_idx]\n",
    "    y_train_fold, y_val_fold = y_train_resampled.iloc[train_idx], y_train_resampled.iloc[test_idx]\n",
    "\n",
    "    # Train the model on the training fold\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation fold\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Evaluate the model on the validation fold\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_val_pred)\n",
    "    class_report_fold = classification_report(y_val_fold, y_val_pred)\n",
    "    confusion_mat_fold = confusion_matrix(y_val_fold, y_val_pred)\n",
    "\n",
    "    # Store the evaluation results for this fold\n",
    "    accuracies.append(accuracy_fold)\n",
    "    class_reports.append(class_report_fold)\n",
    "    confusion_matrices.append(confusion_mat_fold)\n",
    "\n",
    "# Calculate the average accuracy and report for all folds\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "average_class_report = \"\\n\\n\".join(class_reports)\n",
    "average_confusion_matrix = sum(confusion_matrices)\n",
    "\n",
    "print(f'Average Accuracy: {average_accuracy}')\n",
    "print('Average Classification Report:\\n', average_class_report)\n",
    "print('Average Confusion Matrix:\\n', average_confusion_matrix)\n",
    "\n",
    "# Now you can evaluate the model on the test set if needed\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_class_report = classification_report(y_test, y_pred)\n",
    "test_confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Classification Report:\\n', test_class_report)\n",
    "print('Test Confusion Matrix:\\n', test_confusion_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645536f-3885-438a-a820-7df8c9554548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79911c6d-e907-4286-bb22-51261c3e6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25138a22-e92b-4267-ab0a-6f72b93564b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stratified k-fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # Adjust the number of splits as needed\n",
    "\n",
    "# Initialize lists to store evaluation metrics across all folds\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "roc_auc_list = []\n",
    "conf_matrix_list = []\n",
    "\n",
    "# Model Building and Cross-validation\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Address Class Imbalance with SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "    smote = SMOTE(sampling_strategy=0.6, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Create interaction terms\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    X_resampled_poly = poly.fit_transform(X_resampled)\n",
    "\n",
    "    # Initialize and train a random forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=150, max_depth=30, random_state=42)\n",
    "    clf.fit(X_resampled_poly, y_resampled)\n",
    "\n",
    "    # Create interaction terms for test data as well\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_test_poly)\n",
    "\n",
    "    # Evaluate the model using different metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test_poly)[:, 1])\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "    conf_matrix_list.append(conf_matrix)\n",
    "\n",
    "# Calculate the average metrics across all folds\n",
    "avg_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "avg_precision = sum(precision_list) / len(precision_list)\n",
    "avg_recall = sum(recall_list) / len(recall_list)\n",
    "avg_f1 = sum(f1_list) / len(f1_list)\n",
    "avg_roc_auc = sum(roc_auc_list) / len(roc_auc_list)\n",
    "\n",
    "# Calculate the average confusion matrix\n",
    "avg_conf_matrix = sum(conf_matrix_list) / len(conf_matrix_list)\n",
    "\n",
    "# Print the average metrics\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.2f}\")\n",
    "print(f\"Average ROC AUC: {avg_roc_auc:.2f}\")\n",
    "\n",
    "# Print the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(avg_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca751e-bb86-4a5e-9432-e46ef2054201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247703a-e1c7-45fd-89b1-582ff2a4f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5abb9-8a10-484e-a4ba-9ec47d6704cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "# Address class imbalance using SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create a StratifiedKFold object for stratified cross-validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with your chosen hyperparameters\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.4, max_depth=5, random_state=42)\n",
    "\n",
    "# Initialize variables to store results\n",
    "accuracies = []\n",
    "roc_auc_scores = []  # Added for ROC AUC\n",
    "reports = []\n",
    "confusion_matrices = []  # Added for confusion matrices\n",
    "\n",
    "# Perform stratified cross-validation\n",
    "for train_index, test_index in stratified_kfold.split(X_resampled, y_resampled):\n",
    "    X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "    y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data and evaluate the model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])  # Calculate ROC AUC\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)  # Calculate confusion matrix\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    roc_auc_scores.append(roc_auc)  # Store ROC AUC score\n",
    "    reports.append(report)\n",
    "    confusion_matrices.append(cm)  # Store confusion matrix\n",
    "\n",
    "# Calculate the mean accuracy and ROC AUC, and print the classification reports\n",
    "mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "mean_roc_auc = sum(roc_auc_scores) / len(roc_auc_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean ROC AUC:\", mean_roc_auc)\n",
    "\n",
    "for i, report in enumerate(reports):\n",
    "    print(f\"Classification Report for Fold {i + 1}:\\n\", report)\n",
    "\n",
    "# Print the confusion matrices for each fold\n",
    "for i, cm in enumerate(confusion_matrices):\n",
    "    print(f\"Confusion Matrix for Fold {i + 1}:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3d95a-ffb8-434c-a88d-ab4295f6cdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6bf19-940f-4dba-a60a-013f1d1c0331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network for classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7820343-11ef-4263-b649-f87166072e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variables\n",
    "regression_features = [\n",
    "    'DOY', 'OP_UNIQUE_CARRIER', 'CRS_DEP_TIME', 'AIR_TIME', 'Day_Type',\n",
    "    'Average Wind Gust', 'Average Precipitation', 'Min Temperature (°C)',\n",
    "    'Weather_Delayed'\n",
    "]\n",
    "\n",
    "regression_target = 'Estimated_Weather_Delay_Cost'\n",
    "\n",
    "# Separate features and targets\n",
    "X_reg = merged_df_4[regression_features]\n",
    "y_reg = merged_df_4[regression_target]\n",
    "\n",
    "# Separate numerical and categorical columns for regression\n",
    "numerical_cols_reg = ['CRS_DEP_TIME', 'AIR_TIME', 'Average Wind Gust', 'Average Precipitation', 'Min Temperature (°C)', 'DOY']\n",
    "categorical_cols_reg = ['OP_UNIQUE_CARRIER', 'Day_Type']\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "scaler_reg = StandardScaler()\n",
    "X_reg[numerical_cols_reg] = scaler_reg.fit_transform(X_reg[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "encoder_reg = OneHotEncoder(drop='first', sparse=False)\n",
    "X_encoded_reg = encoder_reg.fit_transform(X_reg[categorical_cols_reg])\n",
    "feature_names_reg = encoder_reg.get_feature_names_out(input_features=categorical_cols_reg)\n",
    "X_encoded_reg = pd.DataFrame(X_encoded_reg, columns=feature_names_reg)\n",
    "X_reg = pd.concat([X_reg.drop(columns=categorical_cols_reg), X_encoded_reg], axis=1)\n",
    "\n",
    "# Define a custom Huber activation function\n",
    "def huber_activation(x):\n",
    "    return tf.where(tf.abs(x) < 1, x**2 / 2, tf.abs(x) - 0.5)\n",
    "\n",
    "# Neural network architecture for regression with Huber activation and loss\n",
    "input_reg = Input(shape=(X_reg.shape[1],))\n",
    "hidden_layer_reg = Dense(64, activation=huber_activation)(input_reg)\n",
    "output_reg = Dense(1, activation='linear', name='output_reg')(hidden_layer_reg)\n",
    "\n",
    "# Add an additional hidden layer with more neurons\n",
    "hidden_layer_reg_2 = Dense(128, activation=huber_activation)(hidden_layer_reg)\n",
    "output_reg = Dense(1, activation='linear', name='output_reg')(hidden_layer_reg_2)\n",
    "\n",
    "# Compile the model with Huber loss\n",
    "model = Model(inputs=input_reg, outputs=output_reg)\n",
    "model.compile(optimizer='adam', loss=Huber(), metrics=['mae', 'mse'])\n",
    "\n",
    "# Train the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'R-squared (R^2): {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ca788-559d-4f96-aabf-ae60a84d5f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad7873-934f-45c9-b305-5ea5b59d4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression to forecast Estimated_Weather_Delay_Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487c45a-2d5e-4471-af06-108fe1456569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select features and target variable for regression\n",
    "regression_features = [\n",
    "    'DOY', 'OP_UNIQUE_CARRIER', 'CRS_DEP_TIME', 'AIR_TIME', 'Day_Type',\n",
    "    'Average Wind Gust', 'Average Precipitation', 'Min Temperature (°C)',\n",
    "    'Weather_Delayed'  # Include Weather_Delayed as a feature for regression\n",
    "]\n",
    "regression_target = 'Estimated_Weather_Delay_Cost'\n",
    "\n",
    "# Separate numerical and categorical columns for regression\n",
    "regression_numerical_cols = ['CRS_DEP_TIME', 'AIR_TIME', 'Average Wind Gust', 'Average Precipitation', 'Min Temperature (°C)', 'DOY' \n",
    "                             ,'Weather_Delayed'\n",
    "                            ]\n",
    "regression_categorical_cols = ['OP_UNIQUE_CARRIER', 'Day_Type']\n",
    "\n",
    "# Select features and target variable for regression\n",
    "X_reg = merged_df_4[regression_features]\n",
    "y_reg = merged_df_4[regression_target]\n",
    "\n",
    "# Separate numerical and categorical columns for regression\n",
    "numerical_cols_reg = ['CRS_DEP_TIME', 'AIR_TIME', 'Average Wind Gust', 'Average Precipitation', 'Min Temperature (°C)', 'DOY', \n",
    "                      'Weather_Delayed'\n",
    "                     ]\n",
    "categorical_cols_reg = ['OP_UNIQUE_CARRIER', 'Day_Type']\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "scaler_reg = StandardScaler()\n",
    "X_reg[numerical_cols_reg] = scaler_reg.fit_transform(X_reg[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "encoder_reg = OneHotEncoder(drop='first', sparse=False)\n",
    "X_encoded_reg = encoder_reg.fit_transform(X_reg[categorical_cols_reg])\n",
    "feature_names_reg = encoder_reg.get_feature_names_out(input_features=categorical_cols_reg)\n",
    "X_encoded_reg = pd.DataFrame(X_encoded_reg, columns=feature_names_reg)\n",
    "X_reg = pd.concat([X_reg.drop(columns=categorical_cols_reg), X_encoded_reg], axis=1)\n",
    "\n",
    "\n",
    "# Create a KFold object for cross-validation for regression\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Regressor with quantile loss (Huber approximation)\n",
    "regressor = GradientBoostingRegressor(n_estimators=10, learning_rate=0.4, max_depth=12, loss='quantile', alpha=0.5, random_state=42)\n",
    "\n",
    "# Initialize variables to store results\n",
    "mae_scores = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Perform cross-validation for regression\n",
    "for train_index, test_index in kf.split(X_reg):\n",
    "    X_train_reg, X_test_reg = X_reg.iloc[train_index], X_reg.iloc[test_index]\n",
    "    y_train_reg, y_test_reg = y_reg.iloc[train_index], y_reg.iloc[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    regressor.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "    # Make predictions on the test data and evaluate the model\n",
    "    y_pred_reg = regressor.predict(X_test_reg)\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "    mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "    r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "    # Store regression metrics\n",
    "    mae_scores.append(mae)\n",
    "    mse_scores.append(mse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Calculate the mean regression metrics and print the results\n",
    "mean_mae = sum(mae_scores) / len(mae_scores)\n",
    "mean_mse = sum(mse_scores) / len(mse_scores)\n",
    "mean_r2 = sum(r2_scores) / len(r2_scores)\n",
    "print(\"Mean MAE:\", mean_mae)\n",
    "print(\"Mean MSE:\", mean_mse)\n",
    "print(\"Mean R^2:\", mean_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53496b0-5951-43f8-b440-8c3f8d539d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd66d1d-7487-47ae-8138-81a64eb7ce76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b32be-74e5-42ca-8838-6211da8d5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction of CMIP6 data / Quantile delta mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42344d-44ce-4d85-8e9f-8933a8b189c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile mapping and quantile delta mapping are two techniques used in climate science and hydrology \n",
    "# to adjust simulated or modeled data to better match observed data. \n",
    "# These methods are often employed to correct biases or discrepancies between model outputs and real-world observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca688968-e89d-4031-b106-a71b5626288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ERA5 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea302a-396a-408a-bd37-39dbc2ab2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min temperature 2003-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e9798-0cc9-4d8e-9b0e-5368f634bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "mintemp_ds_314 = nc.Dataset('./ERA5_data/ERA5_min2mtemp_3-14.nc', 'r')\n",
    "mintemp_ds_314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93372f4-26d8-4232-b424-0a2e0de433a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dimname, dimobj in mintemp_ds_314.dimensions.items():\n",
    "    print(f\"{dimname}: {len(dimobj)}\")\n",
    "\n",
    "# List variables\n",
    "print(\"\\nVariables:\")\n",
    "for varname, varobj in mintemp_ds_314.variables.items():\n",
    "    print(f\"{varname}: {varobj.shape} - {varobj.dtype}\")\n",
    "\n",
    "# List global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attrname in mintemp_ds_314.ncattrs():\n",
    "    print(f\"{attrname}: {getattr(mintemp_ds_314, attrname)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17a877-6224-4105-bac5-95c5f21b87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "hist_mintemp_ds = nc.Dataset('./ERA5_data/ERA5_min2mtemp_3-14.nc', 'r')\n",
    "\n",
    "# Extract time and values\n",
    "time_values = hist_mintemp_ds.variables['time'][:]\n",
    "hist_mintemp_values = hist_mintemp_ds.variables['mn2t'][:, 0, 0]\n",
    "\n",
    "# Filter data until August 31, 2023\n",
    "end_date = pd.to_datetime(\"2014-12-31\")\n",
    "filtered_indices = time_values <= pd.Timestamp(end_date).timestamp()\n",
    "\n",
    "# Convert time values to a human-readable format (you can adjust this as needed)\n",
    "hours = time_values[filtered_indices] % 24\n",
    "dates = pd.to_datetime(time_values[filtered_indices], unit='h', origin='1900-01-01')\n",
    "dates += pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Create a DataFrame\n",
    "hist_mintemp_df = pd.DataFrame({'Date': dates, 'Hist Min Temperature': hist_mintemp_values[filtered_indices]})\n",
    "\n",
    "# Group by date and calculate the min for each day\n",
    "hist_mintemp_df = hist_mintemp_df.groupby(hist_mintemp_df['Date'].dt.date)['Hist Min Temperature'].agg(['min']).reset_index()\n",
    "hist_mintemp_df.columns = ['Date', 'Hist Min Temperature']\n",
    "\n",
    "# Print the DataFrame with min values per day\n",
    "print(hist_mintemp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ce19c-43de-4fde-a3c0-339101f182bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert temeprature to °C\n",
    "hist_mintemp_df['Hist Min Temperature (°C)'] = hist_mintemp_df['Hist Min Temperature'] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5f6bb-b94a-4946-98cc-b2f12d53dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to a datetime type (if it's not already)\n",
    "hist_mintemp_df['Date'] = pd.to_datetime(hist_mintemp_df['Date'])\n",
    "\n",
    "# Filter the DataFrame to include only rows until 2014-12-31\n",
    "hist_mintemp_df = hist_mintemp_df[hist_mintemp_df['Date'] <= '2014-12-31']\n",
    "hist_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce0943-3c4c-463f-9234-22e0c196e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windspeed 2003-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70b3a5-3794-4162-9fff-b9440e179725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "hist_wind_ds = nc.Dataset('./ERA5_data/ERA5_10mwindgust_3-14.nc', 'r')\n",
    "hist_wind_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd79f8-1bba-4a4c-a8e5-02fe9347dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dimname, dimobj in hist_wind_ds.dimensions.items():\n",
    "    print(f\"{dimname}: {len(dimobj)}\")\n",
    "\n",
    "# List variables\n",
    "print(\"\\nVariables:\")\n",
    "for varname, varobj in hist_wind_ds.variables.items():\n",
    "    print(f\"{varname}: {varobj.shape} - {varobj.dtype}\")\n",
    "\n",
    "# List global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attrname in hist_wind_ds.ncattrs():\n",
    "    print(f\"{attrname}: {getattr(hist_wind_ds, attrname)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9120b9-275e-47d8-9ee1-0b44972ef211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "hist_wind_ds = nc.Dataset('./ERA5_data/ERA5_10mwindgust_3-14.nc', 'r')\n",
    "\n",
    "# Extract time and wind gust values\n",
    "time_values = hist_wind_ds.variables['time'][:]\n",
    "hist_wind_gust_values = hist_wind_ds.variables['fg10'][:, 0, 0]\n",
    "\n",
    "# Filter data until August 31, 2023\n",
    "end_date = pd.to_datetime(\"2014-12-31\")\n",
    "filtered_indices = time_values <= pd.Timestamp(end_date).timestamp()\n",
    "\n",
    "# Convert time values to a human-readable format (you can adjust this as needed)\n",
    "hours = time_values[filtered_indices] % 24\n",
    "dates = pd.to_datetime(time_values[filtered_indices], unit='h', origin='1900-01-01')\n",
    "dates += pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Create a DataFrame\n",
    "hist_wind_df = pd.DataFrame({'Date': dates, 'Hist Wind Gust': hist_wind_gust_values[filtered_indices]})\n",
    "\n",
    "# Group by date and calculate both the maximum and average wind gust values for each day\n",
    "hist_wind_df = hist_wind_df.groupby(hist_wind_df['Date'].dt.date)['Hist Wind Gust'].agg(['mean']).reset_index()\n",
    "hist_wind_df.columns = ['Date', 'Hist Average Wind Gust']\n",
    "\n",
    "# Print the DataFrame with both maximum and average wind gust values per day\n",
    "print(hist_wind_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae0e12-622a-48fc-96fd-5ed3d25939c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to a datetime type (if it's not already)\n",
    "hist_wind_df['Date'] = pd.to_datetime(hist_wind_df['Date'])\n",
    "\n",
    "# Filter the DataFrame to include only rows until 2014-12-31\n",
    "hist_wind_df = hist_wind_df[hist_wind_df['Date'] <= '2014-12-31']\n",
    "hist_wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7862e6f-2ee0-46f2-bc45-33a9574dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical precipitation rate 2003-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d49ab9-0d5e-4787-90dd-bcecd39e3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "hist_prec_ds = nc.Dataset('./ERA5_data/ERA5_maxtotalprec_3-14.nc', 'r')\n",
    "hist_prec_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4f737-a1a2-403c-872d-41e44f499ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "print(\"Dimensions:\")\n",
    "for dimname, dimobj in hist_prec_ds.dimensions.items():\n",
    "    print(f\"{dimname}: {len(dimobj)}\")\n",
    "\n",
    "# List variables\n",
    "print(\"\\nVariables:\")\n",
    "for varname, varobj in hist_prec_ds.variables.items():\n",
    "    print(f\"{varname}: {varobj.shape} - {varobj.dtype}\")\n",
    "\n",
    "# List global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attrname in hist_prec_ds.ncattrs():\n",
    "    print(f\"{attrname}: {getattr(hist_prec_ds, attrname)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919851e5-cf75-4fab-983d-68151b2b8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "hist_prec_ds = nc.Dataset('./ERA5_data/ERA5_maxtotalprec_3-14.nc', 'r')\n",
    "\n",
    "# Extract time and wind gust values\n",
    "time_values = hist_prec_ds.variables['time'][:]\n",
    "hist_prec_values = hist_prec_ds.variables['mxtpr'][:, 0, 0]\n",
    "\n",
    "# Filter data until August 31, 2023\n",
    "end_date = pd.to_datetime(\"2014-12-31\")\n",
    "filtered_indices = time_values <= pd.Timestamp(end_date).timestamp()\n",
    "\n",
    "# Convert time values to a human-readable format (you can adjust this as needed)\n",
    "hours = time_values[filtered_indices] % 24\n",
    "dates = pd.to_datetime(time_values[filtered_indices], unit='h', origin='1900-01-01')\n",
    "dates += pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Create a DataFrame\n",
    "hist_prec_df = pd.DataFrame({'Date': dates, 'Hist Precipitation': hist_prec_values[filtered_indices]})\n",
    "\n",
    "# Group by date and calculate both the maximum and average wind gust values for each day\n",
    "hist_prec_df = hist_prec_df.groupby(hist_prec_df['Date'].dt.date)['Hist Precipitation'].agg(['mean']).reset_index()\n",
    "hist_prec_df.columns = ['Date', 'Hist Average Precipitation']\n",
    "\n",
    "# Print the DataFrame with both maximum and average wind gust values per day\n",
    "print(hist_prec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0f032-bbf9-49f0-8768-ac5236382548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to a datetime type (if it's not already)\n",
    "hist_prec_df['Date'] = pd.to_datetime(hist_prec_df['Date'])\n",
    "\n",
    "# Filter the DataFrame to include only rows until 2014-12-31\n",
    "hist_prec_df = hist_prec_df[hist_prec_df['Date'] <= '2014-12-31']\n",
    "hist_prec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44db3d-5e1e-4e65-beba-c9e46010b376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f232f-ee39-4523-b9d7-302a6674e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CMIP6 data 2003-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aab1a6-7ac5-4a4a-8458-39d592306ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbfc63-8026-4d58-bb52-e4ffe1e5e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/hist_mintemp_3-14.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af712df1-378e-4a84-a037-5c3b68f5fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_hist_mintemp_ds = nc.Dataset('./CMIP6_data/hist_mintemp_3-14.nc', 'r')\n",
    "CMIP_hist_mintemp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efa1cd-1f10-405a-8bf2-8b84dae8785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_hist_mintemp_ds.variables['lat'][:]\n",
    "lon_values = CMIP_hist_mintemp_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_hist_mintemp_ds.variables['time'][:]\n",
    "temperature_data = CMIP_hist_mintemp_ds.variables['tasmin'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_hist_mintemp_ds.variables['time'].units\n",
    "time_calendar = CMIP_hist_mintemp_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_hist_mintemp_df = pd.DataFrame({'Day': time_in_days, 'CMIP Hist Temperature': temperature_data})\n",
    "\n",
    "CMIP_hist_mintemp_df['Day'] = pd.to_datetime(CMIP_hist_mintemp_df['Day'].astype(str)).dt.date\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_hist_mintemp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd28fd9-54e8-40da-b82a-3f82452486b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change format to datetime\n",
    "CMIP_hist_mintemp_df['Day'] = pd.to_datetime(CMIP_hist_mintemp_df['Day'].astype(str)).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4af16e-0238-4aba-b4f6-5adb11ce7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert temperature to °C\n",
    "CMIP_hist_mintemp_df['CMIP Hist Temperature (C°)'] = CMIP_hist_mintemp_df['CMIP Hist Temperature'] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c84a07-c56c-417f-8eae-562226752655",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_hist_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f3239-d675-40e8-b6ce-3d3954ee0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind gust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c678825-a149-466e-ad79-cf60ba013606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/hist_windsp_3-14.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7360d-d677-4e95-aac5-254f33e018a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_hist_wind_ds = nc.Dataset('./CMIP6_data/hist_windsp_3-14.nc', 'r')\n",
    "CMIP_hist_wind_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a08bf-f892-471a-92dc-dab907e3a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_hist_wind_ds.variables['lat'][:]\n",
    "lon_values = CMIP_hist_wind_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_hist_wind_ds.variables['time'][:]\n",
    "wind_data = CMIP_hist_wind_ds.variables['sfcWind'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_hist_wind_ds.variables['time'].units\n",
    "time_calendar = CMIP_hist_wind_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_hist_wind_df = pd.DataFrame({'Day': time_in_days, 'CMIP Hist Wind': wind_data})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_hist_wind_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f58d20-286c-47eb-8f96-d6c242d03522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert fromat to datetime\n",
    "CMIP_hist_wind_df['Day'] = pd.to_datetime(CMIP_hist_wind_df['Day'].astype(str)).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bcc0c-6c35-4b76-9015-c3d496d00246",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_hist_wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff3c37-b367-42bb-91d5-ccd5d1e746f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07967b-08a1-4a70-9de5-f26bc9a886f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/hist_prec_3-14.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abcae8-a017-41bc-be4b-05c3e463917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_hist_prec_ds = nc.Dataset('./CMIP6_data/hist_prec_3-14.nc', 'r')\n",
    "CMIP_hist_prec_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda0487-054c-4a87-be5c-b717caff2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_hist_prec_ds.variables['lat'][:]\n",
    "lon_values = CMIP_hist_prec_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_hist_prec_ds.variables['time'][:]\n",
    "prec_data = CMIP_hist_prec_ds.variables['pr'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_hist_prec_ds.variables['time'].units\n",
    "time_calendar = CMIP_hist_prec_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_hist_prec_df = pd.DataFrame({'Day': time_in_days, 'CMIP Hist Precipitation': prec_data})\n",
    "\n",
    "CMIP_hist_prec_df['Day'] = pd.to_datetime(CMIP_hist_prec_df['Day'].astype(str)).dt.date\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_hist_prec_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dd261-2c15-4112-982f-4a5271e379cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Future data SSP 1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2e9de-abdc-4866-9332-ea84781db72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6418b42-6c78-4967-acf5-d1dfb3afeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/ssp126_mintemp_15-30.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fbc0a-e6ae-4ff5-8b80-ceb99c02b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_SSP126_mintemp_ds = nc.Dataset('./CMIP6_data/ssp126_mintemp_15-30.nc', 'r')\n",
    "CMIP_SSP126_mintemp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccba8d-0ae8-42f3-9aa2-0f630f1ce57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_SSP126_mintemp_ds.variables['lat'][:]\n",
    "lon_values = CMIP_SSP126_mintemp_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_SSP126_mintemp_ds.variables['time'][:]\n",
    "temperature_data = CMIP_SSP126_mintemp_ds.variables['tasmin'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_SSP126_mintemp_ds.variables['time'].units\n",
    "time_calendar = CMIP_SSP126_mintemp_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_SSP126_mintemp_df = pd.DataFrame({'Day': time_in_days, 'CMIP SSP126 Temperature': temperature_data})\n",
    "\n",
    "CMIP_SSP126_mintemp_df['Day'] = pd.to_datetime(CMIP_SSP126_mintemp_df['Day'].astype(str)).dt.date\n",
    "\n",
    "CMIP_SSP126_mintemp_df['Day'] = pd.to_datetime(CMIP_SSP126_mintemp_df['Day'])\n",
    "\n",
    "CMIP_SSP126_mintemp_df = CMIP_SSP126_mintemp_df[CMIP_SSP126_mintemp_df['Day'] >= '2019-01-01']\n",
    "\n",
    "CMIP_SSP126_mintemp_df['CMIP SSP126 Temperature (°C)'] = CMIP_SSP126_mintemp_df['CMIP SSP126 Temperature'] - 273.15\n",
    "\n",
    "CMIP_SSP126_mintemp_df.drop('CMIP SSP126 Temperature', axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_SSP126_mintemp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a1aaf-1772-4926-ba81-65248268d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind gust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6301db5-5c6d-46a5-914b-fa6791f6fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/ssp126_windsp_15-30.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af001c64-1989-4df2-a5e7-a9f83c159edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_SSP126_wg_ds = nc.Dataset('./CMIP6_data/ssp126_windsp_15-30.nc', 'r')\n",
    "CMIP_SSP126_wg_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a3794-2cf9-464d-9ce5-eae0f7dfb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_SSP126_wg_ds.variables['lat'][:]\n",
    "lon_values = CMIP_SSP126_wg_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_SSP126_wg_ds.variables['time'][:]\n",
    "wg_data = CMIP_SSP126_wg_ds.variables['sfcWind'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_SSP126_wg_ds.variables['time'].units\n",
    "time_calendar = CMIP_SSP126_wg_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_SSP126_wg_df = pd.DataFrame({'Day': time_in_days, 'CMIP SSP126 Wind Gust': wg_data})\n",
    "\n",
    "CMIP_SSP126_wg_df['Day'] = pd.to_datetime(CMIP_SSP126_wg_df['Day'].astype(str)).dt.date\n",
    "\n",
    "CMIP_SSP126_wg_df['Day'] = pd.to_datetime(CMIP_SSP126_wg_df['Day'])\n",
    "\n",
    "CMIP_SSP126_wg_df = CMIP_SSP126_wg_df[CMIP_SSP126_wg_df['Day'] >= '2019-01-01']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_SSP126_wg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f101f6-7815-4355-ae03-599f3cc7d2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd8879-cadd-4f0e-b5f3-885b13f800a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235a8a8-fab1-446e-9e60-d75cb5904417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/ssp126_prec_15-30.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3022252-0f14-4e57-b1d1-fb91eb3acaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_SSP126_prec_ds = nc.Dataset('./CMIP6_data/ssp126_prec_15-30.nc', 'r')\n",
    "CMIP_SSP126_prec_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb092d7-9381-4bbb-9192-e94e2bbc4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_SSP126_prec_ds.variables['lat'][:]\n",
    "lon_values = CMIP_SSP126_prec_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_SSP126_prec_ds.variables['time'][:]\n",
    "prec_data = CMIP_SSP126_prec_ds.variables['pr'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_SSP126_prec_ds.variables['time'].units\n",
    "time_calendar = CMIP_SSP126_prec_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_SSP126_prec_df = pd.DataFrame({'Day': time_in_days, 'CMIP SSP126 Precipitation Rate': prec_data})\n",
    "\n",
    "CMIP_SSP126_prec_df['Day'] = pd.to_datetime(CMIP_SSP126_prec_df['Day'].astype(str)).dt.date\n",
    "\n",
    "CMIP_SSP126_prec_df['Day'] = pd.to_datetime(CMIP_SSP126_prec_df['Day'])\n",
    "\n",
    "CMIP_SSP126_prec_df = CMIP_SSP126_prec_df[CMIP_SSP126_prec_df['Day'] >= '2019-01-01']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_SSP126_prec_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c968c93-8a5f-4abd-9909-9be112e3f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP 585 min temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b1ad30-8ecf-4626-a2f3-a6c402adde55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/ssp585_mintemp_15-30.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de487f-12b3-4609-a457-67a3308a6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_SSP585_mintemp_ds = nc.Dataset('./CMIP6_data/ssp585_mintemp_15-30.nc', 'r')\n",
    "CMIP_SSP585_mintemp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4f1e4-f051-457e-9d81-50b638474dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_SSP585_mintemp_ds.variables['lat'][:]\n",
    "lon_values = CMIP_SSP585_mintemp_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_SSP585_mintemp_ds.variables['time'][:]\n",
    "temperature_data = CMIP_SSP585_mintemp_ds.variables['tasmin'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_SSP585_mintemp_ds.variables['time'].units\n",
    "time_calendar = CMIP_SSP585_mintemp_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_SSP585_mintemp_df = pd.DataFrame({'Day': time_in_days, 'CMIP SSP585 Temperature': temperature_data})\n",
    "\n",
    "CMIP_SSP585_mintemp_df['Day'] = pd.to_datetime(CMIP_SSP585_mintemp_df['Day'].astype(str)).dt.date\n",
    "\n",
    "CMIP_SSP585_mintemp_df['Day'] = pd.to_datetime(CMIP_SSP585_mintemp_df['Day'])\n",
    "\n",
    "CMIP_SSP585_mintemp_df = CMIP_SSP585_mintemp_df[CMIP_SSP585_mintemp_df['Day'] >= '2019-01-01']\n",
    "\n",
    "CMIP_SSP585_mintemp_df['CMIP SSP585 Temperature (°C)'] = CMIP_SSP585_mintemp_df['CMIP SSP585 Temperature'] - 273.15\n",
    "\n",
    "CMIP_SSP585_mintemp_df.drop('CMIP SSP585 Temperature', axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_SSP585_mintemp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314cf064-d81b-4b6b-8077-14c11b83e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP585 - wind gust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176839e-0751-4eeb-b03f-589a9fd17bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/ssp585_windsp_15-30.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861984f-baed-4020-9b1a-8fc02331df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_SSP585_wg_ds = nc.Dataset('./CMIP6_data/ssp585_windsp_15-30.nc', 'r')\n",
    "CMIP_SSP585_wg_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06b7e2-50e2-4590-bc8e-fb37ff2e1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_SSP585_wg_ds.variables['lat'][:]\n",
    "lon_values = CMIP_SSP585_wg_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_SSP585_wg_ds.variables['time'][:]\n",
    "wg_data = CMIP_SSP585_wg_ds.variables['sfcWind'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_SSP585_wg_ds.variables['time'].units\n",
    "time_calendar = CMIP_SSP585_wg_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_SSP585_wg_df = pd.DataFrame({'Day': time_in_days, 'CMIP SSP585 Wind Gust': wg_data})\n",
    "\n",
    "CMIP_SSP585_wg_df['Day'] = pd.to_datetime(CMIP_SSP585_wg_df['Day'].astype(str)).dt.date\n",
    "\n",
    "CMIP_SSP585_wg_df['Day'] = pd.to_datetime(CMIP_SSP585_wg_df['Day'])\n",
    "\n",
    "CMIP_SSP585_wg_df = CMIP_SSP585_wg_df[CMIP_SSP585_wg_df['Day'] >= '2019-01-01']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_SSP585_wg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0dd0fa-90b0-4583-b9d1-a316c5854df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP585 - precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94832138-63e8-4931-95e8-4253cf5c6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file for reading\n",
    "with nc.Dataset('./CMIP6_data/ssp585_prec_15-30.nc', 'r') as data:\n",
    "    # Get a list of variable names\n",
    "    variable_names = list(data.variables.keys())\n",
    "\n",
    "# Print the variable names\n",
    "print(\"Variables in the NetCDF file:\")\n",
    "for var_name in variable_names:\n",
    "    print(var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fa7b9-72ae-4c03-a5a2-69663f0a1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "CMIP_SSP585_prec_ds = nc.Dataset('./CMIP6_data/ssp585_prec_15-30.nc', 'r')\n",
    "CMIP_SSP585_prec_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a51d09-7720-49b3-9d81-2da899b9155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude coordinates for New York JFK Airport\n",
    "ny_jfk_lat = 40.6413\n",
    "ny_jfk_lon = -73.7781\n",
    "\n",
    "# Find the nearest latitude and longitude indices in the dataset\n",
    "lat_values = CMIP_SSP585_prec_ds.variables['lat'][:]\n",
    "lon_values = CMIP_SSP585_prec_ds.variables['lon'][:]\n",
    "lat_index = abs(lat_values - ny_jfk_lat).argmin()\n",
    "lon_index = abs(lon_values - ny_jfk_lon).argmin()\n",
    "\n",
    "# Extract time and temperature data\n",
    "time_data = CMIP_SSP585_prec_ds.variables['time'][:]\n",
    "prec_data = CMIP_SSP585_prec_ds.variables['pr'][:, lat_index, lon_index]\n",
    "\n",
    "# Convert the time data to a more understandable format\n",
    "time_units = CMIP_SSP585_prec_ds.variables['time'].units\n",
    "time_calendar = CMIP_SSP585_prec_ds.variables['time'].calendar\n",
    "time_in_days = nc.num2date(time_data, units=time_units, calendar=time_calendar)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "CMIP_SSP585_prec_df = pd.DataFrame({'Day': time_in_days, 'CMIP SSP585 Precipitation Rate': prec_data})\n",
    "\n",
    "CMIP_SSP585_prec_df['Day'] = pd.to_datetime(CMIP_SSP585_prec_df['Day'].astype(str)).dt.date\n",
    "\n",
    "CMIP_SSP585_prec_df['Day'] = pd.to_datetime(CMIP_SSP585_prec_df['Day'])\n",
    "\n",
    "CMIP_SSP585_prec_df = CMIP_SSP585_prec_df[CMIP_SSP585_prec_df['Day'] >= '2019-01-01']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "CMIP_SSP585_prec_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11708d09-4a80-48ac-b7ff-10e6c135c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column in dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111753d-3f79-4703-9118-af3dbe3b7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2b01a-1282-4239-a791-0a57062a6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mintemp_df.drop('Hist Min Temperature', axis=1, inplace=True)\n",
    "hist_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8e62b-da6e-484d-87f7-f77d8d71c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_hist_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f2630-1871-4076-b848-54c7b52abb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_hist_mintemp_df.drop('CMIP Hist Temperature', axis=1, inplace=True)\n",
    "CMIP_hist_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68795911-69b0-46fc-b8d0-cfbd77cf9973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ee199-1f0d-4187-b88a-531d264667d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application of Quantile Delta Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c74be1-db02-4442-866c-c9d4925bf64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names and index for the observation DataFrame\n",
    "print(\"Observation DataFrame:\")\n",
    "print(hist_mintemp_df.columns)\n",
    "print(hist_mintemp_df.index.name)  # Check the index name\n",
    "\n",
    "# Print column names and index for the model output DataFrame\n",
    "print(\"\\nModel Output DataFrame:\")\n",
    "print(CMIP_hist_mintemp_df.columns)\n",
    "print(CMIP_hist_mintemp_df.index.name)  # Check the index name\n",
    "\n",
    "# Set the existing index as the index for the observation DataFrame\n",
    "hist_mintemp_df.set_index(hist_mintemp_df.index, inplace=True)\n",
    "\n",
    "# Set the existing index as the index for the model output DataFrame\n",
    "CMIP_hist_mintemp_df.set_index('Day', inplace=True)\n",
    "\n",
    "# Calculate quantiles for past observations\n",
    "quantiles_observation = hist_mintemp_df['Hist Min Temperature (°C)'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "# Calculate quantiles for past model output\n",
    "quantiles_model_output = CMIP_hist_mintemp_df['CMIP Hist Temperature (C°)'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "# Print the calculated quantiles\n",
    "print(\"\\nQuantiles for Past Observations:\")\n",
    "print(quantiles_observation)\n",
    "\n",
    "print(\"\\nQuantiles for Past Model Output:\")\n",
    "print(quantiles_model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c573542-fac3-47bf-99b8-82790b73f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the deltas for each quantile\n",
    "mt_deltas = quantiles_observation - quantiles_model_output\n",
    "\n",
    "# Print the calculated deltas\n",
    "print(\"Deltas:\")\n",
    "print(mt_deltas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ebe4d-e9a0-4d82-b631-b92cff5e030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_deltas = pd.DataFrame(mt_deltas)\n",
    "mt_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4234b-d754-4c5c-a94a-e5462ba2c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for the new row\n",
    "new_values = -0.100355\n",
    "\n",
    "# Adding a new row with index 1.0\n",
    "mt_deltas.loc[1.0] = new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e12f2-c54e-4bbc-8892-19ca4f71c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba95441-843d-48d5-b4e2-eb8e6eaacc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles of future dataset\n",
    "\n",
    "# Set the existing index as the index for the model output DataFrame\n",
    "# CMIP_SSP126_mintemp_df.set_index('Day', inplace=True)\n",
    "\n",
    "# Calculate quantiles for future model output\n",
    "ssp126_mt_quantiles = CMIP_SSP126_mintemp_df['CMIP SSP126 Temperature (°C)'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "print(\"\\nQuantiles for Future Model Output:\")\n",
    "print(ssp126_mt_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b05abe-c4c9-4116-bad3-3e38aa95d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp126_mt_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6bdc19-8575-486c-9eea-94bbf2ea349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform to pandas dataframe\n",
    "ssp126_mt_quantiles = pd.DataFrame(ssp126_mt_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195c716-8cde-41f2-808c-0447f39b4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP126_mintemp_df.iterrows():\n",
    "    # Get the temperature value from CMIP_SSP126_mintemp_df\n",
    "    temp_value = row['CMIP SSP126 Temperature (°C)']\n",
    "    \n",
    "    # Find the quantile index in ssp126_mt_quantiles where the temperature is smaller or equal\n",
    "    quantile_index = ssp126_mt_quantiles[ssp126_mt_quantiles['CMIP SSP126 Temperature (°C)'] >= temp_value].index.min()\n",
    "    \n",
    "    # If there is a match, assign the quantile index to a new column in CMIP_SSP126_mintemp_df\n",
    "    if pd.notna(quantile_index):\n",
    "        CMIP_SSP126_mintemp_df.at[index, 'Quantile Index'] = quantile_index\n",
    "    else:\n",
    "        CMIP_SSP126_mintemp_df.at[index, 'Quantile Index'] = 1.0\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "print(CMIP_SSP126_mintemp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c908f1-39ea-42c0-970e-2db442a31f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP126_mintemp_df.iterrows():\n",
    "    # Get the quantile index from CMIP_SSP126_mintemp_df\n",
    "    quantile_index = row['Quantile Index']\n",
    "    \n",
    "    # Check if the quantile index exists in mt_deltas\n",
    "    if quantile_index in mt_deltas.index:\n",
    "        # If it exists, assign the corresponding value to a new column in CMIP_SSP126_mintemp_df\n",
    "        CMIP_SSP126_mintemp_df.at[index, 'Delta Value'] = mt_deltas.loc[quantile_index, 0]\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "CMIP_SSP126_mintemp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83fa59-9f1e-469a-a639-651b14402a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP126_mintemp_df['Corrected CMIP SSP126 Temperature (°C)'] = CMIP_SSP126_mintemp_df['CMIP SSP126 Temperature (°C)'] + CMIP_SSP126_mintemp_df['Delta Value']\n",
    "\n",
    "CMIP_SSP126_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb893d-1b46-4e21-b150-4cc2d8bffea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af56fa3-18c0-43bc-a292-d07b9d7e7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile Delta Mapping - SSP126 wind gust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780e115-c2bb-47e3-9a30-90493d371ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_hist_wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e07542-4d2c-4e5e-9e4e-8a8c2eb36a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81b5f2-611e-455b-a02b-be629490e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP126_wg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ee66f-6532-4a84-a9f9-3954c8bfc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print column names and index for the observation DataFrame\n",
    "# print(\"Observation DataFrame:\")\n",
    "# print(hist_mintemp_df.columns)\n",
    "# print(hist_mintemp_df.index.name)  # Check the index name\n",
    "\n",
    "# # Print column names and index for the model output DataFrame\n",
    "# print(\"\\nModel Output DataFrame:\")\n",
    "# print(CMIP_hist_mintemp_df.columns)\n",
    "# print(CMIP_hist_mintemp_df.index.name)  # Check the index name\n",
    "\n",
    "# Set the existing index as the index for the observation DataFrame\n",
    "hist_wind_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Set the existing index as the index for the model output DataFrame\n",
    "CMIP_hist_wind_df.set_index('Day', inplace=True)\n",
    "\n",
    "# Calculate quantiles for past observations\n",
    "wg_quantiles_observation = hist_wind_df['Hist Average Wind Gust'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "# Calculate quantiles for past model output\n",
    "wg_quantiles_model_output = CMIP_hist_wind_df['CMIP Hist Wind'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "# Print the calculated quantiles\n",
    "print(\"\\nQuantiles for Past Observations:\")\n",
    "print(wg_quantiles_observation)\n",
    "\n",
    "print(\"\\nQuantiles for Past Model Output:\")\n",
    "print(wg_quantiles_model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671ee89-307a-4b7e-9cd7-3589c7d819b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the deltas for each quantile\n",
    "wg_deltas = wg_quantiles_observation - wg_quantiles_model_output\n",
    "\n",
    "# Print the calculated deltas\n",
    "print(\"Deltas:\")\n",
    "print(wg_deltas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514d972-2cf7-4cf5-911b-0c284b0cd4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_wg_delta = pd.DataFrame(wg_deltas)\n",
    "hist_wg_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fa2c5-53fb-4dc6-8dc6-cd0293e1600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles of future dataset\n",
    "\n",
    "# Calculate quantiles for future model output\n",
    "ssp126_wg_quantiles = CMIP_SSP126_wg_df['CMIP SSP126 Wind Gust'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "print(\"\\nQuantiles for Future Model Output:\")\n",
    "print(ssp126_wg_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6f522-cefc-40a2-855d-cbff447873ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to pandas dataframe\n",
    "\n",
    "ssp126_wg_quantiles = pd.DataFrame(ssp126_wg_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c3104-9c32-4f84-afaf-e2fd6a382fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP126_wg_df.iterrows():\n",
    "    # Get the wg value from CMIP_SSP126_wg_df\n",
    "    wg_value = row['CMIP SSP126 Wind Gust']\n",
    "    \n",
    "    # Find the quantile index in ssp126_mt_quantiles where the temperature is smaller or equal\n",
    "    quantile_index = ssp126_wg_quantiles[ssp126_wg_quantiles['CMIP SSP126 Wind Gust'] >= wg_value].index.min()\n",
    "    \n",
    "    # If there is a match, assign the quantile index to a new column in CMIP_SSP126_mintemp_df\n",
    "    if pd.notna(quantile_index):\n",
    "        CMIP_SSP126_wg_df.at[index, 'Quantile Index'] = quantile_index\n",
    "    else:\n",
    "        CMIP_SSP126_wg_df.at[index, 'Quantile Index'] = 1.0\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "print(CMIP_SSP126_wg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8ae2d-1add-4d07-a6cb-229210632fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_wg_df\n",
    "for index, row in CMIP_SSP126_wg_df.iterrows():\n",
    "    # Get the quantile index from CMIP_SSP126_mintemp_df\n",
    "    quantile_index = row['Quantile Index']\n",
    "    \n",
    "    # Check if the quantile index exists in mt_deltas\n",
    "    if quantile_index in hist_wg_delta.index:\n",
    "        # If it exists, assign the corresponding value to a new column in CMIP_SSP126_wg_df\n",
    "        CMIP_SSP126_wg_df.at[index, 'Delta Value'] = hist_wg_delta.loc[quantile_index, 0]\n",
    "\n",
    "# Display the modified CMIP_SSP126_wg_df\n",
    "print(CMIP_SSP126_wg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece23b3-a75e-47f7-a43d-b119d5c74e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP126_wg_df['Corrected CMIP SSP126 Wind Gust'] = CMIP_SSP126_wg_df['CMIP SSP126 Wind Gust'] + CMIP_SSP126_wg_df['Delta Value']\n",
    "\n",
    "CMIP_SSP126_wg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4292a-b8b6-400f-9e0e-ce0337d7c30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740d5e0-c662-455d-bbbd-8b4b349155f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta Quantile Mapping - SSP126 - Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dad0d-c629-444f-b135-71d5ffbe3406",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ee92b-2e04-41f4-8c6b-4a0dc23beeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_hist_prec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff51c1f2-3083-42f3-9aca-611fdb956ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP126_prec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3e8f6-f318-4d43-a71f-d7d6eff19b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print column names and index for the observation DataFrame\n",
    "# print(\"Observation DataFrame:\")\n",
    "# print(hist_mintemp_df.columns)\n",
    "# print(hist_mintemp_df.index.name)  # Check the index name\n",
    "\n",
    "# # Print column names and index for the model output DataFrame\n",
    "# print(\"\\nModel Output DataFrame:\")\n",
    "# print(CMIP_hist_mintemp_df.columns)\n",
    "# print(CMIP_hist_mintemp_df.index.name)  # Check the index name\n",
    "\n",
    "# Set the existing index as the index for the observation DataFrame\n",
    "hist_prec_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Set the existing index as the index for the model output DataFrame\n",
    "CMIP_hist_prec_df.set_index('Day', inplace=True)\n",
    "\n",
    "# Calculate quantiles for past observations\n",
    "prec_quantiles_observation = hist_prec_df['Hist Average Precipitation'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "# Calculate quantiles for past model output\n",
    "prec_quantiles_model_output = CMIP_hist_prec_df['CMIP Hist Precipitation'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "# Print the calculated quantiles\n",
    "print(\"\\nQuantiles for Past Observations:\")\n",
    "print(prec_quantiles_observation)\n",
    "\n",
    "print(\"\\nQuantiles for Past Model Output:\")\n",
    "print(prec_quantiles_model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f75cad-f736-4347-b8f9-247a5a5aeba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the deltas for each quantile\n",
    "prec_deltas = prec_quantiles_observation - prec_quantiles_model_output\n",
    "\n",
    "# Print the calculated deltas\n",
    "print(\"Deltas:\")\n",
    "print(prec_deltas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8a9a3-e4f2-4ee2-af61-31b24cefac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_deltas = pd.DataFrame(prec_deltas)\n",
    "prec_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b5b55-0bdc-4185-8439-452c233d21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles of future dataset\n",
    "\n",
    "# Set the existing index as the index for the model output DataFrame\n",
    "# CMIP_SSP126_mintemp_df.set_index('Day', inplace=True)\n",
    "\n",
    "# Calculate quantiles for future model output\n",
    "ssp126_prec_quantiles = CMIP_SSP126_prec_df['CMIP SSP126 Precipitation Rate'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "print(\"\\nQuantiles for Future Model Output:\")\n",
    "print(ssp126_prec_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f62d5c-e7f3-4277-b90c-7d88ecd7b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp126_prec_quantiles = pd.DataFrame(ssp126_prec_quantiles)\n",
    "\n",
    "ssp126_prec_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4163e-14a8-4158-a31d-8ff554827f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP126_prec_df.iterrows():\n",
    "    # Get the wg value from CMIP_SSP126_wg_df\n",
    "    prec_value = row['CMIP SSP126 Precipitation Rate']\n",
    "    \n",
    "    # Find the quantile index in ssp126_mt_quantiles where the temperature is smaller or equal\n",
    "    quantile_index = ssp126_prec_quantiles[ssp126_prec_quantiles['CMIP SSP126 Precipitation Rate'] >= prec_value].index.min()\n",
    "    \n",
    "    # If there is a match, assign the quantile index to a new column in CMIP_SSP126_mintemp_df\n",
    "    if pd.notna(quantile_index):\n",
    "        CMIP_SSP126_prec_df.at[index, 'Quantile Index'] = quantile_index\n",
    "    else:\n",
    "        CMIP_SSP126_prec_df.at[index, 'Quantile Index'] = 1.0\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "print(CMIP_SSP126_prec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be41b2-d440-4abd-bb9b-03d2bc9cef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_wg_df\n",
    "for index, row in CMIP_SSP126_prec_df.iterrows():\n",
    "    # Get the quantile index from CMIP_SSP126_mintemp_df\n",
    "    quantile_index = row['Quantile Index']\n",
    "    \n",
    "    # Check if the quantile index exists in mt_deltas\n",
    "    if quantile_index in prec_deltas.index:\n",
    "        # If it exists, assign the corresponding value to a new column in CMIP_SSP126_wg_df\n",
    "        CMIP_SSP126_prec_df.at[index, 'Delta Value'] = prec_deltas.loc[quantile_index, 0]\n",
    "\n",
    "# Display the modified CMIP_SSP126_wg_df\n",
    "print(CMIP_SSP126_prec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ed6f5-805b-4e75-b7b2-dc997b946d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP126_prec_df['Corrected CMIP SSP126 Precipitation Rate'] = CMIP_SSP126_prec_df['CMIP SSP126 Precipitation Rate'] + CMIP_SSP126_prec_df['Delta Value']\n",
    "\n",
    "CMIP_SSP126_prec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533df97-b277-45dd-ba2e-78ec54f8d8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7326743-570e-4761-be28-92ee5a6963d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP585 - Quantile Delta Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a4dd3-8711-48cb-b472-4c90104841a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7077ef0-c263-4ec3-aa67-776cbc3b069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP585_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef1cf4-789f-489c-ae34-d1850fdb5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles of future dataset\n",
    "\n",
    "# Set the existing index as the index for the model output DataFrame\n",
    "# CMIP_SSP126_mintemp_df.set_index('Day', inplace=True)\n",
    "\n",
    "# Calculate quantiles for future model output\n",
    "ssp585_mt_quantiles = CMIP_SSP585_mintemp_df['CMIP SSP585 Temperature (°C)'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "print(\"\\nQuantiles for Future Model Output:\")\n",
    "print(ssp585_mt_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ec141-eae5-4c9b-9885-c9ebf69bb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp585_mt_quantiles = pd.DataFrame(ssp585_mt_quantiles)\n",
    "ssp585_mt_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f9f58-74f1-4b7f-ad6c-1cb7a1bbba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP585_mintemp_df.iterrows():\n",
    "    # Get the temperature value from CMIP_SSP126_mintemp_df\n",
    "    temp_value = row['CMIP SSP585 Temperature (°C)']\n",
    "    \n",
    "    # Find the quantile index in ssp126_mt_quantiles where the temperature is smaller or equal\n",
    "    quantile_index = ssp585_mt_quantiles[ssp585_mt_quantiles['CMIP SSP585 Temperature (°C)'] >= temp_value].index.min()\n",
    "    \n",
    "    # If there is a match, assign the quantile index to a new column in CMIP_SSP126_mintemp_df\n",
    "    if pd.notna(quantile_index):\n",
    "        CMIP_SSP585_mintemp_df.at[index, 'Quantile Index'] = quantile_index\n",
    "    else:\n",
    "        CMIP_SSP585_mintemp_df.at[index, 'Quantile Index'] = 1.0\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "print(CMIP_SSP585_mintemp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8b35f-91d0-4425-bdc9-63fa5732e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP585_mintemp_df.iterrows():\n",
    "    # Get the quantile index from CMIP_SSP126_mintemp_df\n",
    "    quantile_index = row['Quantile Index']\n",
    "    \n",
    "    # Check if the quantile index exists in mt_deltas\n",
    "    if quantile_index in mt_deltas.index:\n",
    "        # If it exists, assign the corresponding value to a new column in CMIP_SSP126_mintemp_df\n",
    "        CMIP_SSP585_mintemp_df.at[index, 'Delta Value'] = mt_deltas.loc[quantile_index, 0]\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "print(CMIP_SSP585_mintemp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d664e-3c6d-4cb2-9ccc-644992ac917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP585_mintemp_df['Corrected CMIP SSP585 Temperature (°C)'] = CMIP_SSP585_mintemp_df['CMIP SSP585 Temperature (°C)'] + CMIP_SSP585_mintemp_df['Delta Value']\n",
    "\n",
    "CMIP_SSP585_mintemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504bf89c-5726-4f0a-87d1-84d9ab2d3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP585 - Quantile Delta Mapping - Wind Gust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592459a3-e7d3-4f8e-9eb9-4c4274d06e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP585_wg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3215d-d924-4b21-ada7-3c060690f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles of future dataset\n",
    "\n",
    "# Set the existing index as the index for the model output DataFrame\n",
    "# CMIP_SSP126_mintemp_df.set_index('Day', inplace=True)\n",
    "\n",
    "# Calculate quantiles for future model output\n",
    "ssp585_wg_quantiles = CMIP_SSP585_wg_df['CMIP SSP585 Wind Gust'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "print(\"\\nQuantiles for Future Model Output:\")\n",
    "print(ssp585_wg_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb5444-951a-4ad9-a62d-2170da474bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp585_wg_quantiles = pd.DataFrame(ssp585_wg_quantiles)\n",
    "\n",
    "ssp585_wg_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8357227-816c-4584-adf4-80929e4c241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP585_wg_df.iterrows():\n",
    "    # Get the wg value from CMIP_SSP126_wg_df\n",
    "    wg_value = row['CMIP SSP585 Wind Gust']\n",
    "    \n",
    "    # Find the quantile index in ssp126_mt_quantiles where the temperature is smaller or equal\n",
    "    quantile_index = ssp585_wg_quantiles[ssp585_wg_quantiles['CMIP SSP585 Wind Gust'] >= wg_value].index.min()\n",
    "    \n",
    "    # If there is a match, assign the quantile index to a new column in CMIP_SSP126_mintemp_df\n",
    "    if pd.notna(quantile_index):\n",
    "        CMIP_SSP585_wg_df.at[index, 'Quantile Index'] = quantile_index\n",
    "    else:\n",
    "        CMIP_SSP585_wg_df.at[index, 'Quantile Index'] = 1.0\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "print(CMIP_SSP585_wg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787955aa-cb4c-42cd-97b5-2bf51ea518a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_wg_df\n",
    "for index, row in CMIP_SSP585_wg_df.iterrows():\n",
    "    # Get the quantile index from CMIP_SSP126_mintemp_df\n",
    "    quantile_index = row['Quantile Index']\n",
    "    \n",
    "    # Check if the quantile index exists in mt_deltas\n",
    "    if quantile_index in hist_wg_delta.index:\n",
    "        # If it exists, assign the corresponding value to a new column in CMIP_SSP126_wg_df\n",
    "        CMIP_SSP585_wg_df.at[index, 'Delta Value'] = hist_wg_delta.loc[quantile_index, 0]\n",
    "\n",
    "# Display the modified CMIP_SSP126_wg_df\n",
    "print(CMIP_SSP585_wg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c65885-a9c3-4d52-9642-5cd1085dc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP585_wg_df['Corrected CMIP SSP585 Wind Gust'] = CMIP_SSP585_wg_df['CMIP SSP585 Wind Gust'] + CMIP_SSP585_wg_df['Delta Value']\n",
    "\n",
    "CMIP_SSP585_wg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa42be-3e01-4b5b-b36b-d2adc2a276a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP585 - Delta Quantile Mapping - Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1d11d-77d1-43e7-86fa-ea4d169afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP585_prec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71fdfc-91e0-4fd5-8e44-54b52c56721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles of future dataset\n",
    "\n",
    "# Calculate quantiles for future model output\n",
    "ssp585_prec_quantiles = CMIP_SSP585_prec_df['CMIP SSP585 Precipitation Rate'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "print(\"\\nQuantiles for Future Model Output:\")\n",
    "print(ssp585_prec_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40040dc-9e5c-46d4-a812-0f72a1359ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp585_prec_quantiles = pd.DataFrame(ssp585_prec_quantiles)\n",
    "\n",
    "ssp585_prec_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0d080-85b3-4fa5-8a9a-e899b6952806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_mintemp_df\n",
    "for index, row in CMIP_SSP585_prec_df.iterrows():\n",
    "    # Get the wg value from CMIP_SSP126_wg_df\n",
    "    prec_value = row['CMIP SSP585 Precipitation Rate']\n",
    "    \n",
    "    # Find the quantile index in ssp126_mt_quantiles where the temperature is smaller or equal\n",
    "    quantile_index = ssp585_prec_quantiles[ssp585_prec_quantiles['CMIP SSP585 Precipitation Rate'] >= prec_value].index.min()\n",
    "    \n",
    "    # If there is a match, assign the quantile index to a new column in CMIP_SSP126_mintemp_df\n",
    "    if pd.notna(quantile_index):\n",
    "        CMIP_SSP585_prec_df.at[index, 'Quantile Index'] = quantile_index\n",
    "    else:\n",
    "        CMIP_SSP585_prec_df.at[index, 'Quantile Index'] = 1.0\n",
    "\n",
    "# Display the modified CMIP_SSP126_mintemp_df\n",
    "print(CMIP_SSP585_prec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db51df-093f-4ef8-a53d-5fa9707e18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of CMIP_SSP126_wg_df\n",
    "for index, row in CMIP_SSP585_prec_df.iterrows():\n",
    "    # Get the quantile index from CMIP_SSP126_mintemp_df\n",
    "    quantile_index = row['Quantile Index']\n",
    "    \n",
    "    # Check if the quantile index exists in mt_deltas\n",
    "    if quantile_index in prec_deltas.index:\n",
    "        # If it exists, assign the corresponding value to a new column in CMIP_SSP126_wg_df\n",
    "        CMIP_SSP585_prec_df.at[index, 'Delta Value'] = prec_deltas.loc[quantile_index, 0]\n",
    "\n",
    "# Display the modified CMIP_SSP126_wg_df\n",
    "print(CMIP_SSP585_prec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87506c13-f39e-4e09-b34b-4baeed5baa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_SSP585_prec_df['Corrected CMIP SSP585 Precipitation Rate'] = CMIP_SSP585_prec_df['CMIP SSP585 Precipitation Rate'] + CMIP_SSP585_prec_df['Delta Value']\n",
    "CMIP_SSP585_prec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842834e-554c-4f85-9d19-ab0a15907493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acca62b-4ec5-4c66-bcfe-e0a4c3608b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87372ad5-713e-429c-bd40-826bed0c66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with corrected SSP126 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196eee85-4838-4178-a942-817f2db5d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'FL_DATE' and 'Date' columns\n",
    "merged_df = df_1.merge(df_2, left_on='FL_DATE', right_on='Date', how='left')\n",
    "\n",
    "# Drop the 'Date' column from the merged dataframe if you don't need it\n",
    "merged_df = merged_df.drop(columns=['Date'])\n",
    "\n",
    "# Now, merged_df contains the Max Wind Gust and Average Wind Gust columns from df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4eb6dd-a8d5-420c-9dcf-5e5e069015b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all corrected climate variable columns on the date\n",
    "\n",
    "corrected_ssp126_df = CMIP_SSP126_mintemp_df.merge(CMIP_SSP126_wg_df, left_on='Day', right_on='Day', how='left')\n",
    "\n",
    "corrected_ssp126_df = corrected_ssp126_df.drop(columns=['CMIP SSP126 Temperature (°C)', 'Quantile Index_x', 'Delta Value_x', 'CMIP SSP126 Wind Gust', 'Quantile Index_y', 'Delta Value_y'])     \n",
    "\n",
    "corrected_ssp126_df = corrected_ssp126_df.merge(CMIP_SSP126_prec_df, left_on='Day', right_on='Day', how='left')\n",
    "\n",
    "corrected_ssp126_df = corrected_ssp126_df.drop(columns=['CMIP SSP126 Precipitation Rate', 'Quantile Index', 'Delta Value'])     \n",
    "\n",
    "corrected_ssp126_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b996278-58e4-4cd6-a9e3-37d90027492d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d419c3-5006-4534-9709-2e49e6c049c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with corrected SSP585 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64abef-5a66-4714-ae70-96ef53087420",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df = CMIP_SSP585_mintemp_df.merge(CMIP_SSP585_wg_df, left_on='Day', right_on='Day', how='left')\n",
    "\n",
    "corrected_ssp585_df = corrected_ssp585_df.drop(columns=['CMIP SSP585 Temperature (°C)', 'Quantile Index_x', 'Delta Value_x', 'CMIP SSP585 Wind Gust', 'Quantile Index_y', 'Delta Value_y'])     \n",
    "\n",
    "corrected_ssp585_df = corrected_ssp585_df.merge(CMIP_SSP585_prec_df, left_on='Day', right_on='Day', how='left')\n",
    "\n",
    "corrected_ssp585_df = corrected_ssp585_df.drop(columns=['CMIP SSP585 Precipitation Rate', 'Quantile Index', 'Delta Value'])     \n",
    "\n",
    "corrected_ssp585_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302017c-dbd8-4b67-8228-979696f3574a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9738c-f2f6-4edf-bf1e-f63bdd092603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df for each year from 2023 to 2030 with the same flight schedule as in 2022 but the future values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84416cf2-1403-4209-9087-34b9607f7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = df_1[df_1['FL_DATE'].dt.year == 2022]\n",
    "df_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7214a2-8aff-443e-9073-c6e0ee2284f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['ORIGIN', 'DEP_DELAY_NEW', 'CANCELLED', 'WEATHER_DELAY', 'NAS_DELAY', 'Delayed']\n",
    "df_2022 = df_2022.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f0797-2bfc-49ee-b765-45e7c3b3a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column\n",
    "df_2022['DOY'] = pd.to_datetime(df_2022['FL_DATE']).dt.dayofyear\n",
    "df_2022 = df_2022.drop(columns=['FL_DATE'])  # Remove the original 'FL_DATE' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73a090-1d5d-40c9-a44e-ff56c5993331",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2022 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a8413-8d5c-4a55-abe2-9f89ee9ac8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2023 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a5099-250a-44c6-8775-e08229be355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2024 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3acd7-39cb-42c2-9ad5-982a52b9ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2025 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe617116-11fa-4e2e-b6d8-ca55f12f5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2026 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeffb66-0086-4d8d-8d99-3a4286a1c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2027 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e9f62-b0d1-4c4b-acf6-343f32c632fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2028 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2028]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33032f-cec3-44ff-bbd1-c65ab9eeaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2029 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2029]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62cfa9-d00f-4277-8e7c-838006238dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2030 = corrected_ssp126_df[corrected_ssp126_df['Day'].dt.year == 2030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357ff88-24dc-48e3-a3f6-63a6871e9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1a4c1-ff4d-475a-ad27-778177f2f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2030['DOY'] = pd.to_datetime(corrected_ssp126_df_2030['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2030 = corrected_ssp126_df_2030.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f62af-c4b5-49ea-9681-36b14d4fa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2029['DOY'] = pd.to_datetime(corrected_ssp126_df_2029['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2029 = corrected_ssp126_df_2029.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9416353-fabc-4b30-8439-9384011faffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2028['DOY'] = pd.to_datetime(corrected_ssp126_df_2028['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2028 = corrected_ssp126_df_2028.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18380cd8-b54a-4f40-9843-3b4d6787a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct doy because 2028 is a leap year\n",
    "corrected_ssp126_df_2028.loc[corrected_ssp126_df_2028['DOY'] >= 61, 'DOY'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4a1dd-f342-4edd-934a-9ec36f9bef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2027['DOY'] = pd.to_datetime(corrected_ssp126_df_2027['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2027 = corrected_ssp126_df_2027.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1467f66-7612-4fa8-bba6-34ba1688519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2026['DOY'] = pd.to_datetime(corrected_ssp126_df_2026['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2026 = corrected_ssp126_df_2026.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbe73e-f4e5-4a92-b5cf-6c6d8b73c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2025['DOY'] = pd.to_datetime(corrected_ssp126_df_2025['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2025 = corrected_ssp126_df_2025.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6dc7f1-7714-454a-b74a-909601af94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2024['DOY'] = pd.to_datetime(corrected_ssp126_df_2024['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2024 = corrected_ssp126_df_2024.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714a583-3fb2-4648-86ce-1541e4acc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct DOY column because 2024 is a leap year\n",
    "corrected_ssp126_df_2024.loc[corrected_ssp126_df_2024['DOY'] >= 61, 'DOY'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c032bc-9360-48f9-866d-c342d1842fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2023['DOY'] = pd.to_datetime(corrected_ssp126_df_2023['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2023 = corrected_ssp126_df_2023.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c398e0-a115-4d01-a981-5d9ecb0c05c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp126_df_2022['DOY'] = pd.to_datetime(corrected_ssp126_df_2022['Day']).dt.dayofyear\n",
    "corrected_ssp126_df_2022 = corrected_ssp126_df_2022.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45805df0-a9b8-46ef-8cd4-8e2903fd89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2030 = df_2022.merge(corrected_ssp126_df_2030, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335147e-c4e8-41d9-8a84-d33951c699c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2029 = df_2022.merge(corrected_ssp126_df_2029, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cbc15-4a3d-476b-a297-577261948f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2028 = df_2022.merge(corrected_ssp126_df_2028, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8936c-9931-474c-a5d4-cad2ace31d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2027 = df_2022.merge(corrected_ssp126_df_2027, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b11ec-1aa3-45fa-9842-f96cb61a5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2026 = df_2022.merge(corrected_ssp126_df_2026, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bc2c4-4d4c-48f2-92d2-639fcbb8629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2025 = df_2022.merge(corrected_ssp126_df_2025, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d4be2-174b-4d4b-a67e-acb007d2d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2024 = df_2022.merge(corrected_ssp126_df_2024, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b250bd4-380b-463e-878b-92e739ef643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2023 = df_2022.merge(corrected_ssp126_df_2023, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690ca3d-7fb4-4d3f-822b-8b8b30b4fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2022 = df_2022.merge(corrected_ssp126_df_2022, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de338cd6-8e9a-43d4-8270-9a057ca1cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa448d-53e6-4d87-944a-925f834594f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2022, 2031)\n",
    "\n",
    "# Create a dictionary to map old column names to new column names\n",
    "column_mapping = {'Corrected CMIP SSP126 Temperature (°C)': 'Min Temperature (°C)',\n",
    "                  'Corrected CMIP SSP126 Wind Gust': 'Average Wind Gust',\n",
    "                  'Corrected CMIP SSP126 Precipitation Rate': 'Average Precipitation'}\n",
    "\n",
    "# Loop through the years and rename columns\n",
    "for year in years:\n",
    "    locals()[f'corrected_ssp126_df_{year}'].rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba59224-106c-4766-afcd-880615f30d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e3b18-0e52-48a4-b2ec-1efeef2e77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2029 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2029]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074582d-d556-4c38-864e-65e43c860294",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2028 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2028]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62135a4a-458c-4552-8433-355708f4b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2027 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775dd87d-95cd-486e-8ec2-0b0c240cabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2026 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07109754-7da5-4652-8ae8-0e756c8b687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2025 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf8e24-5a4d-4bc5-80a6-8de7250191b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2024 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7035487-36fa-48a2-bb90-33b1f4ea33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2023 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f811721-3e6f-4caf-8589-5d5b1d4a8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2022 = corrected_ssp585_df[corrected_ssp585_df['Day'].dt.year == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676da007-86cf-48e8-ae54-dbd9c34a9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fbe8a-513f-4ddb-b5f0-aabc3d494f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2030['DOY'] = pd.to_datetime(corrected_ssp585_df_2030['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2030 = corrected_ssp585_df_2030.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88340ea-6d9b-4410-a5dd-4d96d8dbad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2029['DOY'] = pd.to_datetime(corrected_ssp585_df_2029['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2029 = corrected_ssp585_df_2029.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb2d51-62bb-4241-b65a-96bcda1803f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2028['DOY'] = pd.to_datetime(corrected_ssp585_df_2028['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2028 = corrected_ssp585_df_2028.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bc499-1069-42ea-8f77-feaa2699a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct DOY column becasue 2028 is a leap year\n",
    "corrected_ssp585_df_2028.loc[corrected_ssp585_df_2028['DOY'] >= 61, 'DOY'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64ea01-65cd-4b52-9665-a2155a7055db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2027['DOY'] = pd.to_datetime(corrected_ssp585_df_2027['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2027 = corrected_ssp585_df_2027.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a29d7-1563-44a7-880d-7144950aabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2026['DOY'] = pd.to_datetime(corrected_ssp585_df_2026['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2026 = corrected_ssp585_df_2026.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491335e6-11cd-4048-b493-d6ffdb286fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2025['DOY'] = pd.to_datetime(corrected_ssp585_df_2025['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2025 = corrected_ssp585_df_2025.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafd1bd-c9dd-4ecc-84c9-12db9280eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2024['DOY'] = pd.to_datetime(corrected_ssp585_df_2024['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2024 = corrected_ssp585_df_2024.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703e558-6f24-4471-8b29-2bf6d247f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the DOY column because 2024 is a leap year\n",
    "corrected_ssp585_df_2024.loc[corrected_ssp585_df_2024['DOY'] >= 61, 'DOY'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47206cc5-8800-4668-a152-0e554b4a149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2023['DOY'] = pd.to_datetime(corrected_ssp585_df_2023['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2023 = corrected_ssp585_df_2023.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21f7a1-add9-4a4c-b3a7-b591ca1f4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Day of Year (DOY) from the 'FL_DATE' column and remove 'FL_DATE' column\n",
    "corrected_ssp585_df_2022['DOY'] = pd.to_datetime(corrected_ssp585_df_2022['Day']).dt.dayofyear\n",
    "corrected_ssp585_df_2022 = corrected_ssp585_df_2022.drop(columns=['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510e6a2-1921-43d6-8197-268cba54481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030 = df_2022.merge(corrected_ssp585_df_2030, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868f446-89bc-4d39-968d-bf494bc90d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2029 = df_2022.merge(corrected_ssp585_df_2029, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7b162-b2c7-4ac7-b753-955a006256be",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2028 = df_2022.merge(corrected_ssp585_df_2028, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3263fd-9861-44a4-ae6f-593313cc985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2027 = df_2022.merge(corrected_ssp585_df_2027, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9c0d6-0552-4ef9-ab1c-7d4013baad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2026 = df_2022.merge(corrected_ssp585_df_2026, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b9eb0-2edf-42e5-847a-745543c0a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2025 = df_2022.merge(corrected_ssp585_df_2025, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca6e82-0fd1-4e25-a123-7026b84a7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2024 = df_2022.merge(corrected_ssp585_df_2024, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4bc35-dfe2-4c76-b889-c5ffbf0d48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2023 = df_2022.merge(corrected_ssp585_df_2023, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f1e0e3-9129-479a-a388-106cac3cc3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2022 = df_2022.merge(corrected_ssp585_df_2022, on='DOY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0a837-f762-4fca-abb7-d0cb4520210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f95493-8eea-4b62-b574-39c070bbbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2022, 2031)\n",
    "\n",
    "# Create a dictionary to map old column names to new column names\n",
    "column_mapping = {'Corrected CMIP SSP585 Temperature (°C)': 'Min Temperature (°C)', 'Corrected CMIP SSP585 Wind Gust': 'Average Wind Gust', 'Corrected CMIP SSP585 Precipitation Rate': 'Average Precipitation'}\n",
    "\n",
    "# Rename the columns using the dictionary in a loop\n",
    "for year in years:\n",
    "    locals()[f'corrected_ssp585_df_{year}'].rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "corrected_ssp585_df_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489a5a7-bb2e-43ce-ac24-e7e65667c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2022, 2031)\n",
    "\n",
    "for year in years:\n",
    "    locals()[f'corrected_ssp126_df_{year}'].drop(columns=['Weather_Delayed'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f5421-1c20-497e-9f0a-4e57cd572695",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2022, 2031)\n",
    "\n",
    "for year in years:\n",
    "    locals()[f'corrected_ssp585_df_{year}'].drop(columns=['Weather_Delayed'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1a55e-0e45-4573-94fb-16a9c03f95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624f596-6c49-49b3-b9be-23a7afde2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the new data with the gradient boost model - predict whether a flight is delayed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932f9a8-6c16-4db1-a313-0a79f108b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ad181-8e5b-4f39-b906-99bcdddb37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_30 = corrected_ssp126_df_2030[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_30[numerical_cols] = scaler.transform(new_X_126_30[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_30 = encoder.transform(new_X_126_30[categorical_cols])\n",
    "new_feature_names_126_30 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_30 = pd.DataFrame(new_X_encoded_126_30, columns=new_feature_names_126_30)\n",
    "new_X_126_30 = pd.concat([new_X_126_30.drop(columns=categorical_cols), new_X_encoded_126_30], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf036f6-420a-478b-8c21-2f31c204bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_29 = corrected_ssp126_df_2029[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_29[numerical_cols] = scaler.transform(new_X_126_29[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_29 = encoder.transform(new_X_126_29[categorical_cols])\n",
    "new_feature_names_126_29 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_29 = pd.DataFrame(new_X_encoded_126_29, columns=new_feature_names_126_29)\n",
    "new_X_126_29 = pd.concat([new_X_126_29.drop(columns=categorical_cols), new_X_encoded_126_29], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf199e-095d-49a0-b0f8-df94c864c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_28 = corrected_ssp126_df_2028[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_28[numerical_cols] = scaler.transform(new_X_126_28[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_28 = encoder.transform(new_X_126_28[categorical_cols])\n",
    "new_feature_names_126_28 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_28 = pd.DataFrame(new_X_encoded_126_28, columns=new_feature_names_126_28)\n",
    "\n",
    "new_X_126_28.reset_index(drop=True, inplace=True)\n",
    "new_X_encoded_126_28.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_X_126_28 = pd.concat([new_X_126_28.drop(columns=categorical_cols), new_X_encoded_126_28], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8c205-1ebd-4a40-99f3-2ad7e21eb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_27 = corrected_ssp126_df_2027[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_27[numerical_cols] = scaler.transform(new_X_126_27[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_27 = encoder.transform(new_X_126_27[categorical_cols])\n",
    "new_feature_names_126_27 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_27 = pd.DataFrame(new_X_encoded_126_27, columns=new_feature_names_126_27)\n",
    "new_X_126_27 = pd.concat([new_X_126_27.drop(columns=categorical_cols), new_X_encoded_126_27], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b04bef-d1bc-4d1f-a277-4fcd23a8237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_26 = corrected_ssp126_df_2026[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_26[numerical_cols] = scaler.transform(new_X_126_26[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_26 = encoder.transform(new_X_126_26[categorical_cols])\n",
    "new_feature_names_126_26 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_26 = pd.DataFrame(new_X_encoded_126_26, columns=new_feature_names_126_26)\n",
    "new_X_126_26 = pd.concat([new_X_126_26.drop(columns=categorical_cols), new_X_encoded_126_26], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557e67f-5336-45d7-989b-2deca0f3f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_25 = corrected_ssp126_df_2025[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_25[numerical_cols] = scaler.transform(new_X_126_25[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_25 = encoder.transform(new_X_126_25[categorical_cols])\n",
    "new_feature_names_126_25 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_25 = pd.DataFrame(new_X_encoded_126_25, columns=new_feature_names_126_25)\n",
    "new_X_126_25 = pd.concat([new_X_126_25.drop(columns=categorical_cols), new_X_encoded_126_25], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4aeb3-3048-4fdf-b55a-1e13384c035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_24 = corrected_ssp126_df_2024[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_24[numerical_cols] = scaler.transform(new_X_126_24[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_24 = encoder.transform(new_X_126_24[categorical_cols])\n",
    "new_feature_names_126_24 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_24 = pd.DataFrame(new_X_encoded_126_24, columns=new_feature_names_126_24)\n",
    "\n",
    "new_X_126_24.reset_index(drop=True, inplace=True)\n",
    "new_X_encoded_126_24.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_X_126_24 = pd.concat([new_X_126_24.drop(columns=categorical_cols), new_X_encoded_126_24], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163d697-57c4-4a64-9778-18340428f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_23 = corrected_ssp126_df_2023[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_23[numerical_cols] = scaler.transform(new_X_126_23[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_23 = encoder.transform(new_X_126_23[categorical_cols])\n",
    "new_feature_names_126_23 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_23 = pd.DataFrame(new_X_encoded_126_23, columns=new_feature_names_126_23)\n",
    "new_X_126_23 = pd.concat([new_X_126_23.drop(columns=categorical_cols), new_X_encoded_126_23], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa6832-bdf5-4d54-8c45-5a7eff039236",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_126_22 = corrected_ssp126_df_2022[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_126_22[numerical_cols] = scaler.transform(new_X_126_22[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_126_22 = encoder.transform(new_X_126_22[categorical_cols])\n",
    "new_feature_names_126_22 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_126_22 = pd.DataFrame(new_X_encoded_126_22, columns=new_feature_names_126_22)\n",
    "new_X_126_22 = pd.concat([new_X_126_22.drop(columns=categorical_cols), new_X_encoded_126_22], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4223cd-333d-4b2f-a813-b8f537a0e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2030['Predicted_Label'] = clf.predict(new_X_126_30)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2030['Probability_Score'] = clf.predict_proba(new_X_126_30)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825cb68-d58f-4d69-a478-ebc63a53e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2029['Predicted_Label'] = clf.predict(new_X_126_29)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2029['Probability_Score'] = clf.predict_proba(new_X_126_29)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1b2c0-afa9-418d-8868-5e116d048552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2028['Predicted_Label'] = clf.predict(new_X_126_28)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2028['Probability_Score'] = clf.predict_proba(new_X_126_28)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e29422-1f6e-49c4-9058-fc1c6ab85331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2027['Predicted_Label'] = clf.predict(new_X_126_27)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2027['Probability_Score'] = clf.predict_proba(new_X_126_27)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509315e0-6b17-429d-b4e4-ec1a1ca5bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2026['Predicted_Label'] = clf.predict(new_X_126_26)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2026['Probability_Score'] = clf.predict_proba(new_X_126_26)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f47609-5ba7-4005-b4e9-b3845c1b6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2025['Predicted_Label'] = clf.predict(new_X_126_25)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2025['Probability_Score'] = clf.predict_proba(new_X_126_25)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fb39d-8267-4714-9822-27c73c571777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2024['Predicted_Label'] = clf.predict(new_X_126_24)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2024['Probability_Score'] = clf.predict_proba(new_X_126_24)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34342af-1c58-401a-bbaf-d31d4db2be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2023['Predicted_Label'] = clf.predict(new_X_126_23)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2023['Probability_Score'] = clf.predict_proba(new_X_126_23)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f7d2b-0f76-4a9a-a40f-2db3ad56027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2022['Predicted_Label'] = clf.predict(new_X_126_22)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp126_df_2022['Probability_Score'] = clf.predict_proba(new_X_126_22)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb204a7-9779-4e0c-a0f2-23f8d08516d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1051a04-8e99-42d9-b391-c6bb9156359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2030['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fcf38-02eb-45d1-90cf-05c9f09b73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2029['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0f8d3-37b0-44dc-b808-06bd7f70f452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2028['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a0c2a-d8d1-481c-8842-8186708305d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2027['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e877a49-0655-4044-a7a7-b4ce7db0c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2026['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3ff97-af8a-42cf-b257-aeb13c781590",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2025['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced4ba6-bcc3-4fc6-9920-eb133f783a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2024['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4424c-8456-4327-a5f6-bd5724f76653",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2023['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f92cc82-8a3e-433e-9d06-b3b71f66f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2022['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0defc-c2d1-446c-a5ab-04c56ea49237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP 585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d6ba1-1525-4c38-9b43-dc44b75a488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_30 = corrected_ssp585_df_2030[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_30[numerical_cols] = scaler.transform(new_X_585_30[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_30 = encoder.transform(new_X_585_30[categorical_cols])\n",
    "new_feature_names_585_30 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_30 = pd.DataFrame(new_X_encoded_585_30, columns=new_feature_names_585_30)\n",
    "new_X_585_30 = pd.concat([new_X_585_30.drop(columns=categorical_cols), new_X_encoded_585_30], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7f7fd-02ea-45d4-a1ea-46f0fd633db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_29 = corrected_ssp585_df_2029[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_29[numerical_cols] = scaler.transform(new_X_585_29[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_29 = encoder.transform(new_X_585_29[categorical_cols])\n",
    "new_feature_names_585_29 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_29 = pd.DataFrame(new_X_encoded_585_29, columns=new_feature_names_585_29)\n",
    "new_X_585_29 = pd.concat([new_X_585_29.drop(columns=categorical_cols), new_X_encoded_585_29], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3bd6c-6607-49b4-8f2f-8fe10e0b9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_28 = corrected_ssp585_df_2028[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_28[numerical_cols] = scaler.transform(new_X_585_28[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_28 = encoder.transform(new_X_585_28[categorical_cols])\n",
    "new_feature_names_585_28 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_28 = pd.DataFrame(new_X_encoded_585_28, columns=new_feature_names_585_28)\n",
    "new_X_585_28 = pd.concat([new_X_585_28.drop(columns=categorical_cols), new_X_encoded_585_28], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5a10f-0dcd-44a8-8186-7df0fe224462",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_27 = corrected_ssp585_df_2027[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_27[numerical_cols] = scaler.transform(new_X_585_27[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_27 = encoder.transform(new_X_585_27[categorical_cols])\n",
    "new_feature_names_585_27 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_27 = pd.DataFrame(new_X_encoded_585_27, columns=new_feature_names_585_27)\n",
    "new_X_585_27 = pd.concat([new_X_585_27.drop(columns=categorical_cols), new_X_encoded_585_27], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c17d6-49a6-40aa-a33d-b0e05796c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_26 = corrected_ssp585_df_2026[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_26[numerical_cols] = scaler.transform(new_X_585_26[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_26 = encoder.transform(new_X_585_26[categorical_cols])\n",
    "new_feature_names_585_26 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_26 = pd.DataFrame(new_X_encoded_585_26, columns=new_feature_names_585_26)\n",
    "new_X_585_26 = pd.concat([new_X_585_26.drop(columns=categorical_cols), new_X_encoded_585_26], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b74bb-b4a8-4291-aa10-f9aa09736f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_25 = corrected_ssp585_df_2025[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_25[numerical_cols] = scaler.transform(new_X_585_25[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_25 = encoder.transform(new_X_585_25[categorical_cols])\n",
    "new_feature_names_585_25 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_25 = pd.DataFrame(new_X_encoded_585_25, columns=new_feature_names_585_25)\n",
    "new_X_585_25 = pd.concat([new_X_585_25.drop(columns=categorical_cols), new_X_encoded_585_25], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e98b88-fd03-456e-a018-6e5996264f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_24 = corrected_ssp585_df_2024[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_24[numerical_cols] = scaler.transform(new_X_585_24[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_24 = encoder.transform(new_X_585_24[categorical_cols])\n",
    "new_feature_names_585_24 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_24 = pd.DataFrame(new_X_encoded_585_24, columns=new_feature_names_585_24)\n",
    "new_X_585_24 = pd.concat([new_X_585_24.drop(columns=categorical_cols), new_X_encoded_585_24], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb1578-7c67-437c-880e-b0f6d3827ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_23 = corrected_ssp585_df_2023[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_23[numerical_cols] = scaler.transform(new_X_585_23[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_23 = encoder.transform(new_X_585_23[categorical_cols])\n",
    "new_feature_names_585_23 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_23 = pd.DataFrame(new_X_encoded_585_23, columns=new_feature_names_585_23)\n",
    "new_X_585_23 = pd.concat([new_X_585_23.drop(columns=categorical_cols), new_X_encoded_585_23], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c99757-42b1-4232-8d85-82278c108e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_585_22 = corrected_ssp585_df_2022[selected_features]\n",
    "\n",
    "# Standardize numerical features\n",
    "new_X_585_22[numerical_cols] = scaler.transform(new_X_585_22[numerical_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_X_encoded_585_22 = encoder.transform(new_X_585_22[categorical_cols])\n",
    "new_feature_names_585_22 = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "new_X_encoded_585_22 = pd.DataFrame(new_X_encoded_585_22, columns=new_feature_names_585_22)\n",
    "new_X_585_22 = pd.concat([new_X_585_22.drop(columns=categorical_cols), new_X_encoded_585_22], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97624815-3242-448e-9c2e-e68a15bd48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2030['Predicted_Label'] = clf.predict(new_X_585_30)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2030['Probability_Score'] = clf.predict_proba(new_X_585_30)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bc089-977a-4d07-abba-8f243505226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2029['Predicted_Label'] = clf.predict(new_X_585_29)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2029['Probability_Score'] = clf.predict_proba(new_X_585_29)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1f2ad-a5e9-431d-bad1-29b99dd8c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2028['Predicted_Label'] = clf.predict(new_X_585_28)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2028['Probability_Score'] = clf.predict_proba(new_X_585_28)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c3a45-e48a-40a5-a3c0-6227b5f42a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2027['Predicted_Label'] = clf.predict(new_X_585_27)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2027['Probability_Score'] = clf.predict_proba(new_X_585_27)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f111eea-fea1-4995-873d-cf40425c2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2026['Predicted_Label'] = clf.predict(new_X_585_26)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2026['Probability_Score'] = clf.predict_proba(new_X_585_26)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8ba64-9529-4c33-a14e-f4019a956608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2025['Predicted_Label'] = clf.predict(new_X_585_25)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2025['Probability_Score'] = clf.predict_proba(new_X_585_25)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc507a47-0dd7-4232-a80c-c58c938769a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2024['Predicted_Label'] = clf.predict(new_X_585_24)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2024['Probability_Score'] = clf.predict_proba(new_X_585_24)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd809d-af2b-42fa-b3a6-5c97b7df1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2023['Predicted_Label'] = clf.predict(new_X_585_23)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2023['Probability_Score'] = clf.predict_proba(new_X_585_23)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3b574-f5f3-47b6-bd34-896e08529b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2022['Predicted_Label'] = clf.predict(new_X_585_22)\n",
    "\n",
    "# If you want probability scores as well\n",
    "corrected_ssp585_df_2022['Probability_Score'] = clf.predict_proba(new_X_585_22)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe349b-89c9-4f0a-a6b5-594579ccb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08f908-5f2d-4ab8-bb07-a7a73815bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2029['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c646cbd-f448-45c5-a3f6-1e1985cbcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2028['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7490e-fc52-4cde-9082-2802c3d6e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2027['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31365c18-8210-4a3d-aedf-ad6dbc7c3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2026['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a783ce-9c38-4083-9915-46320437ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2025['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1d35a-e4d2-4530-9f00-d649d31e9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2024['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f282c-a2aa-4fba-bdbb-dd06cee8cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2023['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b07d1-9212-43ac-bd84-0f86cc1c0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2022['Predicted_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28f94c-e124-4533-ae8a-28a04ab50f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a42b6-717a-48d8-9367-ddd2540f121b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15e1ad-8a78-439d-9c66-70aa0b60f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions for the delay cost - regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864875a-0fa3-41ef-b16d-df91cf975ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp126_df_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7639a3-a772-4443-8a24-360e4dac7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2022, 2031):\n",
    "    locals()[f'corrected_ssp126_df_{year}'].rename(columns={'Predicted_Label': 'Weather_Delayed'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5942a07-6551-4c75-867c-58d899f5e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2022, 2031):\n",
    "    locals()[f'corrected_ssp585_df_{year}'].rename(columns={'Predicted_Label': 'Weather_Delayed'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4442cd-ac76-4cde-802b-a5020ca34150",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397fa54-0485-420a-a57b-7687201e2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108c116-0eab-4a9c-ac04-8a1614bedcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_22 = corrected_ssp126_df_2022[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_22[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_22[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_22 = encoder_reg.transform(X_new_cost_ssp126_22[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_22 = pd.DataFrame(X_encoded_new_cost_ssp126_22, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_22 = pd.concat([X_new_cost_ssp126_22.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_22], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221adf7-73ed-410e-97e1-571912996d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_23 = corrected_ssp126_df_2023[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_23[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_23[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_23 = encoder_reg.transform(X_new_cost_ssp126_23[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_23 = pd.DataFrame(X_encoded_new_cost_ssp126_23, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_23 = pd.concat([X_new_cost_ssp126_23.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_23], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13d453-5225-4115-8ff0-a231f00a4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_24 = corrected_ssp126_df_2024[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_24[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_24[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_24 = encoder_reg.transform(X_new_cost_ssp126_24[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_24 = pd.DataFrame(X_encoded_new_cost_ssp126_24, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_24 = pd.concat([X_new_cost_ssp126_24.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_24], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da5afd-85be-4320-bbd6-a36da6a69bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_25 = corrected_ssp126_df_2025[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_25[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_25[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_25 = encoder_reg.transform(X_new_cost_ssp126_25[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_25 = pd.DataFrame(X_encoded_new_cost_ssp126_25, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_25 = pd.concat([X_new_cost_ssp126_25.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_25], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ab008-49c4-448d-98d7-8a26b28e9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_26 = corrected_ssp126_df_2026[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_26[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_26[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_26 = encoder_reg.transform(X_new_cost_ssp126_26[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_26 = pd.DataFrame(X_encoded_new_cost_ssp126_26, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_26 = pd.concat([X_new_cost_ssp126_26.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_26], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20964a4f-c75d-4538-9148-62948042371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_27 = corrected_ssp126_df_2027[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_27[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_27[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_27 = encoder_reg.transform(X_new_cost_ssp126_27[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_27 = pd.DataFrame(X_encoded_new_cost_ssp126_27, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_27 = pd.concat([X_new_cost_ssp126_27.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_27], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8091e-c7a4-47d3-923c-519f20ece9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_28 = corrected_ssp126_df_2028[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_28[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_28[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_28 = encoder_reg.transform(X_new_cost_ssp126_28[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_28 = pd.DataFrame(X_encoded_new_cost_ssp126_28, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_28 = pd.concat([X_new_cost_ssp126_28.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_28], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac915e4-ab14-4e2e-9323-8f22a8ea7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_29 = corrected_ssp126_df_2029[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_29[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_29[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_29 = encoder_reg.transform(X_new_cost_ssp126_29[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_29 = pd.DataFrame(X_encoded_new_cost_ssp126_29, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_29 = pd.concat([X_new_cost_ssp126_29.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_29], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92458a1-4cd4-4816-bffb-9107543ba78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp126_30 = corrected_ssp126_df_2030[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp126_30[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp126_30[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp126_30 = encoder_reg.transform(X_new_cost_ssp126_30[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp126_30 = pd.DataFrame(X_encoded_new_cost_ssp126_30, columns=feature_names_reg)\n",
    "X_new_cost_ssp126_30 = pd.concat([X_new_cost_ssp126_30.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp126_30], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51f1c1-4815-42d0-9a75-169273918cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 585 cost prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e9df3-6ffa-4564-8892-6be4758863fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_22 = corrected_ssp585_df_2022[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_22[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_22[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_22 = encoder_reg.transform(X_new_cost_ssp585_22[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_22 = pd.DataFrame(X_encoded_new_cost_ssp585_22, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_22 = pd.concat([X_new_cost_ssp585_22.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_22], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de439f0c-83ae-4b2c-aedb-9de5f98e413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_23 = corrected_ssp585_df_2023[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_23[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_23[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_23 = encoder_reg.transform(X_new_cost_ssp585_23[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_23 = pd.DataFrame(X_encoded_new_cost_ssp585_23, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_23 = pd.concat([X_new_cost_ssp585_23.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_23], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582010f5-0ad7-4ff5-8386-2c6f552c1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_24 = corrected_ssp585_df_2024[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_24[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_24[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_24 = encoder_reg.transform(X_new_cost_ssp585_24[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_24 = pd.DataFrame(X_encoded_new_cost_ssp585_24, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_24 = pd.concat([X_new_cost_ssp585_24.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_24], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e51fe-c247-406e-993c-fd39e7d7a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_25 = corrected_ssp585_df_2025[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_25[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_25[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_25 = encoder_reg.transform(X_new_cost_ssp585_25[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_25 = pd.DataFrame(X_encoded_new_cost_ssp585_25, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_25 = pd.concat([X_new_cost_ssp585_25.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_25], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91cf44-0142-4cb4-8a16-856d1e8e18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_26 = corrected_ssp585_df_2026[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_26[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_26[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_26 = encoder_reg.transform(X_new_cost_ssp585_26[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_26 = pd.DataFrame(X_encoded_new_cost_ssp585_26, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_26 = pd.concat([X_new_cost_ssp585_26.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_26], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e67989-7a0e-42e7-90e1-1fadc2e336a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_27 = corrected_ssp585_df_2027[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_27[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_27[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_27 = encoder_reg.transform(X_new_cost_ssp585_27[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_27 = pd.DataFrame(X_encoded_new_cost_ssp585_27, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_27 = pd.concat([X_new_cost_ssp585_27.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_27], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c538e9-44af-4c90-881f-53f68bca340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_28 = corrected_ssp585_df_2028[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_28[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_28[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_28 = encoder_reg.transform(X_new_cost_ssp585_28[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_28 = pd.DataFrame(X_encoded_new_cost_ssp585_28, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_28 = pd.concat([X_new_cost_ssp585_28.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_28], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aece15-ef6d-482f-a30a-53367d68fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_29 = corrected_ssp585_df_2029[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_29[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_29[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_29 = encoder_reg.transform(X_new_cost_ssp585_29[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_29 = pd.DataFrame(X_encoded_new_cost_ssp585_29, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_29 = pd.concat([X_new_cost_ssp585_29.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_29], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbff752-7d83-494a-9607-fa0ab1f63c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_cost_ssp585_30 = corrected_ssp585_df_2030[regression_features]\n",
    "\n",
    "# Standardize numerical features for regression\n",
    "X_new_cost_ssp585_30[numerical_cols_reg] = scaler_reg.transform(X_new_cost_ssp585_30[numerical_cols_reg])\n",
    "\n",
    "# Handle categorical features with one-hot encoding for regression\n",
    "X_encoded_new_cost_ssp585_30 = encoder_reg.transform(X_new_cost_ssp585_30[categorical_cols_reg])\n",
    "X_encoded_new_cost_ssp585_30 = pd.DataFrame(X_encoded_new_cost_ssp585_30, columns=feature_names_reg)\n",
    "X_new_cost_ssp585_30 = pd.concat([X_new_cost_ssp585_30.drop(columns=categorical_cols_reg), X_encoded_new_cost_ssp585_30], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51734a29-62ec-44eb-8e58-69544b325afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2022['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_22)\n",
    "corrected_ssp126_df_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a811fe-c22d-44e1-b90f-ae7810463cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2023['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644b8c8-4108-4632-9fdd-93fa07de3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2024['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152964d-ca58-4af6-85f6-39a16043e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2025['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fb3eb-3f27-4809-83ef-5348ade8d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2026['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba962fd6-e86b-4591-aee9-c2b52c96da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2027['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c310d76-e933-4926-b500-e2c8584d8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2028['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5006e6e-9920-40c6-a938-8ffd7b07695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2029['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba0e37-72c3-430c-9d5b-8463c5186fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp126_df_2030['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ab7db-2dea-49de-8b1e-f6068e87973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2022['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp126_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc2881-e1da-4a19-9d2a-def9a6a14d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2023['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06506ab-dca0-4981-a242-8020e8ca0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2024['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72f6f9-ce10-4d07-bd51-e971703b2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2025['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6fead-e321-4f3c-ad54-b1bbb4f74139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2026['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3cae1-f24c-4098-bcf0-5375447b37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2027['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b03011-749d-4eaa-990b-e7f1e6945970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2028['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35135c5-b8db-4043-bbfe-56d0bff62b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2029['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240ead7-2dc9-4be9-a896-c2a021e6bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataset\n",
    "corrected_ssp585_df_2030['Predicted_Delay_Cost'] = regressor.predict(X_new_cost_ssp585_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274f4e1-db97-434e-901c-b12218d81d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ssp585_df_2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ded47-56e0-41e2-918c-eab6e5934afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddf8a8-6966-4993-a20e-e3173cb9f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d9ba2-82c8-4154-83b3-02478c6d96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9af90-c157-44ff-b1ee-5f757244ea41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List to store the data for the new dataframe\n",
    "data = []\n",
    "\n",
    "# Iterate through each year's dataframe\n",
    "for year in range(2023, 2031):\n",
    "    # Get the current dataframe\n",
    "    current_df = globals()[f'corrected_ssp126_df_{year}']\n",
    "\n",
    "    # Count occurrences of value 1 in \"Predicted_Label_2\" column\n",
    "    weather_delays_count = current_df['Weather_Delayed'].eq(1).sum()\n",
    "\n",
    "    # Append data to the list\n",
    "    data.append({'year': year, 'weather_delays_126': weather_delays_count})\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "new_table_df = pd.DataFrame(data)\n",
    "\n",
    "# Print or use the new dataframe as needed\n",
    "print(new_table_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2a679-c37a-4ca4-8bd7-5ca9b3ab9871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the float_format to display full decimal representation rounded to two decimal places\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# List to store the data for the new dataframe\n",
    "data_2 = []\n",
    "\n",
    "# Iterate through each year's dataframe\n",
    "for year in range(2023, 2031):\n",
    "    # Get the current dataframe\n",
    "    current_df = globals()[f'corrected_ssp126_df_{year}']\n",
    "\n",
    "    # Sum values in the \"Predicted_Delay_Cost\" column\n",
    "    total_delay_cost = current_df['Predicted_Delay_Cost'].sum()\n",
    "\n",
    "    # Append data to the list\n",
    "    data_2.append({'year': year, 'Total Delay Cost': total_delay_cost})\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "new_table_df_cost = pd.DataFrame(data_2)\n",
    "\n",
    "# Print or use the new dataframe as needed\n",
    "print(new_table_df_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449cf35-1d80-4501-877c-550244540eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List to store the data for the new dataframe\n",
    "data_585 = []\n",
    "\n",
    "# Iterate through each year's dataframe\n",
    "for year in range(2023, 2031):\n",
    "    # Get the current dataframe\n",
    "    current_df_585 = globals()[f'corrected_ssp585_df_{year}']\n",
    "\n",
    "    # Count occurrences of value 1 in \"Predicted_Label_2\" column\n",
    "    weather_delays_count = current_df_585['Weather_Delayed'].eq(1).sum()\n",
    "\n",
    "    # Append data to the list\n",
    "    data_585.append({'year': year, 'weather_delays_585': weather_delays_count})\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "new_table_df_585 = pd.DataFrame(data_585)\n",
    "\n",
    "# Print or use the new dataframe as needed\n",
    "print(new_table_df_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904fb93-3250-412b-87c3-27d7cedd02b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the float_format to display full decimal representation rounded to two decimal places\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# List to store the data for the new dataframe\n",
    "data_585_2 = []\n",
    "\n",
    "# Iterate through each year's dataframe\n",
    "for year in range(2023, 2031):\n",
    "    # Get the current dataframe\n",
    "    current_df_585 = globals()[f'corrected_ssp585_df_{year}']\n",
    "\n",
    "    # Sum values in the \"Predicted_Delay_Cost\" column\n",
    "    total_delay_cost_585 = current_df_585['Predicted_Delay_Cost'].sum()\n",
    "\n",
    "    # Append data to the list\n",
    "    data_585_2.append({'year': year, 'Total Delay Cost': total_delay_cost_585})\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "new_table_df_cost_585 = pd.DataFrame(data_585_2)\n",
    "\n",
    "# Print or use the new dataframe as needed\n",
    "print(new_table_df_cost_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f508d197-9005-4667-ac87-607d2ffe7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_df = new_table_df.merge(new_table_df_585, on='year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392239cc-9000-49ae-b3d0-e80fbab84b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533498a-4237-4e21-8623-b244f0e73d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_df_cost = new_table_df_cost.merge(new_table_df_cost_585, on='year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdf0a2-2aa2-49b8-be81-82bb2115c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_df_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f443b7-2386-461d-b00f-7bff12c9ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with the old and new column names\n",
    "column_mapping = {'Total Delay Cost_x': 'Delay Cost 126', 'Total Delay Cost_y': 'Delay Cost 585'}\n",
    "\n",
    "# Use the rename method to rename the columns\n",
    "new_table_df_cost.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f9591-327e-4e66-ad2c-b0c492d5394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_df_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428de67-5476-4e4c-b60a-a73e24c007f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45229bb1-39ab-436f-8182-cf9bace7a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from the date\n",
    "merged_df_5['year'] = merged_df_5['FL_DATE'].dt.year\n",
    "\n",
    "# Group by year and calculate the frequency of delays\n",
    "result_df = merged_df_5.groupby('year')['Weather_Delayed'].sum().reset_index()\n",
    "result_df.rename(columns={'Weather_Delayed': 'weather_delays_historical'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a39ab47-dc8f-4fb7-a34f-a81cc948b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[result_df['year'] <= 2022]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833a853-5b84-4bdb-a314-2751c3488b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract year from the date\n",
    "merged_df_5['year'] = merged_df_5['FL_DATE'].dt.year\n",
    "\n",
    "# Group by year and calculate the frequency of delays\n",
    "result_df_cost = merged_df_5.groupby('year')['Estimated_Weather_Delay_Cost'].sum().reset_index()\n",
    "result_df_cost.rename(columns={'Estimated_Weather_Delay_Cost': 'Delay Cost Historical'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac1a83-c165-44d9-9b2c-3c96ee83e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40219bc9-8fc4-43fb-a49b-c4dc73d757ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging past and future delays\n",
    "delays_year_df = pd.merge(result_df, new_table_df, on='year', how='outer')\n",
    "delays_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b3599-b3d8-4303-a970-b88951378549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and values for the 1st standard deviation\n",
    "columns_to_calculate = ['weather_delays_126', 'weather_delays_585']\n",
    "\n",
    "for column in columns_to_calculate:\n",
    "    # Exclude NaN values\n",
    "    non_nan_values = delays_year_df[column].dropna()\n",
    "\n",
    "    # Calculate mean\n",
    "    mean_value = non_nan_values.mean()\n",
    "\n",
    "    # Calculate 1st standard deviation\n",
    "    std_dev_value = non_nan_values.std()\n",
    "\n",
    "    # Calculate values for 1st standard deviation\n",
    "    lower_bound = mean_value - std_dev_value\n",
    "    upper_bound = mean_value + std_dev_value\n",
    "\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Mean: {mean_value}\")\n",
    "    print(f\"1st Standard Deviation: {std_dev_value}\")\n",
    "    print(f\"Lower Bound: {lower_bound}\")\n",
    "    print(f\"Upper Bound: {upper_bound}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e6e52-397b-438d-a82d-e9039fd3dc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d59d44-3b05-40df-aaac-cf2396bbe52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging past and future delay costs\n",
    "cost_year_df = pd.merge(result_df_cost, new_table_df_cost, on='year', how='outer')\n",
    "cost_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1633a-2a8e-4c83-b4ae-40019b3e8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the value in the \"Delay Cost Historical\" column for the year 2023 with NaN\n",
    "cost_year_df.loc[cost_year_df['year'] == 2023, 'Delay Cost Historical'] = np.nan\n",
    "cost_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d9e92-fee5-4775-8632-3730bc45ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate mean, std, and bounds\n",
    "def calculate_stats(column):\n",
    "    non_nan_values = column.dropna()\n",
    "    mean_value = non_nan_values.mean()\n",
    "    std_value = non_nan_values.std()\n",
    "    lower_bound = mean_value - std_value\n",
    "    upper_bound = mean_value + std_value\n",
    "    return mean_value, std_value, lower_bound, upper_bound\n",
    "\n",
    "# Calculate stats for Delay Cost 126\n",
    "mean_126, std_126, lower_126, upper_126 = calculate_stats(cost_year_df['Delay Cost 126'])\n",
    "\n",
    "# Calculate stats for Delay Cost 585\n",
    "mean_585, std_585, lower_585, upper_585 = calculate_stats(cost_year_df['Delay Cost 585'])\n",
    "\n",
    "# Print the results\n",
    "print(\"Delay Cost 126:\")\n",
    "print(f\"Mean: {mean_126}\")\n",
    "print(f\"1st Std Dev: {std_126}\")\n",
    "print(f\"Lower Bound: {lower_126}\")\n",
    "print(f\"Upper Bound: {upper_126}\")\n",
    "print(\"\\nDelay Cost 585:\")\n",
    "print(f\"Mean: {mean_585}\")\n",
    "print(f\"1st Std Dev: {std_585}\")\n",
    "print(f\"Lower Bound: {lower_585}\")\n",
    "print(f\"Upper Bound: {upper_585}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ebe8c-9385-402b-86e0-2d55c6deaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of ticket that need to be sold to cover the cost - SSP 1.26\n",
    "43092860.025846064/416.17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f88ff6-9d16-4af1-a42f-b489e87149c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of ticket that need to be sold to cover the cost - SSP 5.85\n",
    "41994056.25977469/416.17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5bb12-d65f-44fc-bc96-760d47534664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (Your existing code for data processing)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot historical values\n",
    "plt.plot(delays_year_df['year'], delays_year_df['weather_delays_historical'], color='gray', linestyle='-', marker='o', label='Historical')\n",
    "\n",
    "# Plot average lines and spreads for non-NaN values\n",
    "plt.plot(delays_year_df.loc[10:, 'year'], [avg_delay_585] * len(delays_year_df.loc[10:]), color='b', linestyle='--', label='Avg Delay')\n",
    "plt.fill_between(delays_year_df.loc[10:, 'year'], avg_delay_585 - std_delay_585, avg_delay_585 + std_delay_585, where=~delays_year_df['weather_delays_585'].isna()[10:], color='lightblue', alpha=0.5, label='Spread')\n",
    "\n",
    "# Plot individual data points\n",
    "plt.scatter(delays_year_df.loc[10:, 'year'], delays_year_df.loc[10:, 'weather_delays_585'], color='darkblue', label='Data', marker='o', s=50)\n",
    "\n",
    "# Plot error bars for individual data points\n",
    "plt.errorbar(delays_year_df.loc[10:, 'year'], delays_year_df.loc[10:, 'weather_delays_585'], yerr=std_delay_585, linestyle='', color='darkblue', label='Std Dev', capsize=4)\n",
    "\n",
    "plt.xlabel('Year [-]', fontname='Times New Roman', fontsize=16)\n",
    "plt.ylabel('Number of Delays [-]', fontname='Times New Roman', fontsize=16)\n",
    "plt.legend(loc='upper left', title=None)\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis ticks for every second year\n",
    "plt.xticks(delays_year_df['year'][::2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810d2ad-8ae4-48d6-a629-1fae3925846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average and standard deviation for weather_delays_126\n",
    "avg_delay_126 = delays_year_df.loc[10:, 'weather_delays_126'].mean()\n",
    "std_delay_126 = delays_year_df.loc[10:, 'weather_delays_126'].std()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot historical values\n",
    "plt.plot(delays_year_df['year'], delays_year_df['weather_delays_historical'], color='gray', linestyle='-', marker='o', label='Historical')\n",
    "\n",
    "# Plot average lines and spreads for non-NaN values\n",
    "plt.plot(delays_year_df.loc[10:, 'year'], [avg_delay_126] * len(delays_year_df.loc[10:]), color='r', linestyle='--', label='Avg Delay')\n",
    "plt.fill_between(delays_year_df.loc[10:, 'year'], avg_delay_126 - std_delay_126, avg_delay_126 + std_delay_126, where=~delays_year_df['weather_delays_126'].isna()[10:], color='lightcoral', alpha=0.5, label='Spread')\n",
    "\n",
    "# Plot individual data points\n",
    "plt.scatter(delays_year_df.loc[10:, 'year'], delays_year_df.loc[10:, 'weather_delays_126'], color='darkred', label='Data', marker='o', s=50)\n",
    "\n",
    "# Plot error bars for individual data points\n",
    "plt.errorbar(delays_year_df.loc[10:, 'year'], delays_year_df.loc[10:, 'weather_delays_126'], yerr=std_delay_126, linestyle='', color='darkred', label='Std Dev', capsize=4)\n",
    "\n",
    "plt.xlabel('Year [-]', fontname='Times New Roman', fontsize=16)\n",
    "plt.ylabel('Number of Delays [-]', fontname='Times New Roman', fontsize=16)\n",
    "plt.legend(loc='upper left', title=None)\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis ticks for every second year\n",
    "plt.xticks(delays_year_df['year'][::2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6c6fd-2797-4ed4-b086-23055f0814fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average and standard deviation for weather_delays_126\n",
    "avg_cost_126 = cost_year_df.loc[10:, 'Delay Cost 126'].mean()\n",
    "std_cost_126 = cost_year_df.loc[10:, 'Delay Cost 126'].std()\n",
    "\n",
    "# Convert cost values to millions\n",
    "cost_year_df['Delay Cost Historical (Millions)'] = cost_year_df['Delay Cost Historical'] / 1000000\n",
    "cost_year_df['Delay Cost 126 (Millions)'] = cost_year_df['Delay Cost 126'] / 1000000\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot historical values\n",
    "plt.plot(cost_year_df['year'], cost_year_df['Delay Cost Historical (Millions)'], color='gray', linestyle='-', marker='o', label='Historical')\n",
    "\n",
    "# Plot average line and spread for non-NaN values\n",
    "plt.plot(cost_year_df.loc[10:, 'year'], [avg_cost_126 / 1000000] * len(cost_year_df.loc[10:]), color='r', linestyle='--', label='Avg Delay Cost')\n",
    "plt.fill_between(cost_year_df.loc[10:, 'year'], (avg_cost_126 - std_cost_126) / 1000000, (avg_cost_126 + std_cost_126) / 1000000, where=~cost_year_df['Delay Cost 126'].isna()[10:], color='lightcoral', alpha=0.5, label='Spread')\n",
    "\n",
    "# Plot individual data points\n",
    "plt.scatter(cost_year_df.loc[10:, 'year'], cost_year_df.loc[10:, 'Delay Cost 126 (Millions)'], color='darkred', label='Data', marker='o', s=50)\n",
    "\n",
    "# Plot error bars for individual data points\n",
    "plt.errorbar(cost_year_df.loc[10:, 'year'], cost_year_df.loc[10:, 'Delay Cost 126 (Millions)'], yerr=std_cost_126 / 1000000, linestyle='', color='darkred', label='Std Dev', capsize=4)\n",
    "\n",
    "plt.xlabel('Year [-]', fontname='Times New Roman', fontsize=16)\n",
    "plt.ylabel('Cost of Delay [$ Million]', fontname='Times New Roman', fontsize=16)\n",
    "plt.legend(loc='upper left', title=None)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis ticks for every second year\n",
    "plt.xticks(cost_year_df['year'][::2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f4db6a-1490-4731-9c7c-372c60042bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average and standard deviation for weather_delays_585\n",
    "avg_cost_585 = cost_year_df.loc[10:, 'Delay Cost 585'].mean()\n",
    "std_cost_585 = cost_year_df.loc[10:, 'Delay Cost 585'].std()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot historical values\n",
    "plt.plot(cost_year_df['year'], cost_year_df['Delay Cost Historical'] / 1e6, color='gray', linestyle='-', marker='o', label='Historical')  # Divide by 1e6 to convert to millions\n",
    "\n",
    "# Plot average lines and spreads for non-NaN values\n",
    "plt.plot(cost_year_df.loc[10:, 'year'], [avg_cost_585 / 1e6] * len(cost_year_df.loc[10:]), color='b', linestyle='--', label='Avg Delay Cost')  # Divide by 1e6\n",
    "plt.fill_between(cost_year_df.loc[10:, 'year'], (avg_cost_585 - std_cost_585) / 1e6, (avg_cost_585 + std_cost_585) / 1e6, where=~cost_year_df['Delay Cost 585'].isna()[10:], color='lightblue', alpha=0.5, label='Spread')  # Divide by 1e6\n",
    "\n",
    "# Plot individual data points\n",
    "plt.scatter(cost_year_df.loc[10:, 'year'], cost_year_df.loc[10:, 'Delay Cost 585'] / 1e6, color='darkblue', label='Data', marker='o', s=50)  # Divide by 1e6\n",
    "\n",
    "# Plot error bars for individual data points\n",
    "plt.errorbar(cost_year_df.loc[10:, 'year'], cost_year_df.loc[10:, 'Delay Cost 585'] / 1e6, yerr=std_cost_585 / 1e6, linestyle='', color='darkblue', label='Std Dev', capsize=4)  # Divide by 1e6\n",
    "\n",
    "plt.xlabel('Year [-]', fontname='Times New Roman', fontsize=16)\n",
    "plt.ylabel('Cost of Delay [$ Million]', fontname='Times New Roman', fontsize=16)  # Updated ylabel\n",
    "plt.legend(loc='upper left', title=None)\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis ticks for every second year\n",
    "plt.xticks(cost_year_df['year'][::2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c6a99-7b0a-4500-9457-bd9491bc6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate kendall tau and spearman rank correlation for weather delays results\n",
    "\n",
    "column_126 = delays_year_df['weather_delays_126']\n",
    "column_585 = delays_year_df['weather_delays_585']\n",
    "\n",
    "# Drop NaN values from both year and delay columns\n",
    "valid_data = delays_year_df.dropna(subset=['year', 'weather_delays_126', 'weather_delays_585'])\n",
    "\n",
    "# Extract valid columns\n",
    "valid_year = valid_data['year']\n",
    "valid_126 = valid_data['weather_delays_126']\n",
    "valid_585 = valid_data['weather_delays_585']\n",
    "\n",
    "# Calculate Kendall tau and p-value\n",
    "tau_126, p_value_126 = kendalltau(valid_year, valid_126)\n",
    "\n",
    "# Calculate Spearman rank correlation and p-value\n",
    "rho_126, p_value_126_spearman = spearmanr(valid_year, valid_126)\n",
    "\n",
    "print(f\"Kendall tau for weather_delays_126: {tau_126}, p-value: {p_value_126}\")\n",
    "print(f\"Spearman rank correlation for weather_delays_126: {rho_126}, p-value: {p_value_126_spearman}\")\n",
    "\n",
    "# Repeat the process for weather_delays_585\n",
    "tau_585, p_value_585 = kendalltau(valid_year, valid_585)\n",
    "rho_585, p_value_585_spearman = spearmanr(valid_year, valid_585)\n",
    "\n",
    "print(f\"Kendall tau for weather_delays_585: {tau_585}, p-value: {p_value_585}\")\n",
    "print(f\"Spearman rank correlation for weather_delays_585: {rho_585}, p-value: {p_value_585_spearman}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a8edc-fae7-47cd-856b-7ae18f7dd87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b29d7-4e9c-46d4-b3b7-bb6b3f2c7373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddbfc12-fc9f-4c29-8b8a-f0d55ccab17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PLotting the cost per carrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117168e8-3b47-4639-991c-debffc31bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2023 = corrected_ssp126_df_2023.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2023['Average_Delay_Cost_Per_Flight'] = grouped_data_2023['sum'] / grouped_data_2023['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2023 = grouped_data_2023.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02de34-2eff-481a-a462-ef8633034b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2024 = corrected_ssp126_df_2024.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2024['Average_Delay_Cost_Per_Flight'] = grouped_data_2024['sum'] / grouped_data_2024['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2024 = grouped_data_2024.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88dc3f-ebf7-46ff-a791-76e1621969c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2025 = corrected_ssp126_df_2025.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2025['Average_Delay_Cost_Per_Flight'] = grouped_data_2025['sum'] / grouped_data_2025['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2025 = grouped_data_2025.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a72601-34c0-42e8-ac87-118891a75324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2026 = corrected_ssp126_df_2026.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2026['Average_Delay_Cost_Per_Flight'] = grouped_data_2026['sum'] / grouped_data_2026['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2026 = grouped_data_2026.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2026)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1791a-0d77-42de-8696-32f82d90a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2027 = corrected_ssp126_df_2027.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2027['Average_Delay_Cost_Per_Flight'] = grouped_data_2027['sum'] / grouped_data_2027['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2027 = grouped_data_2027.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2027)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b2557-d984-40a0-9d49-23b069c1b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2028 = corrected_ssp126_df_2028.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2028['Average_Delay_Cost_Per_Flight'] = grouped_data_2028['sum'] / grouped_data_2028['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2028 = grouped_data_2028.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2028)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09816505-9f56-42a0-8e14-0828c2a7e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2029 = corrected_ssp126_df_2029.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2029['Average_Delay_Cost_Per_Flight'] = grouped_data_2029['sum'] / grouped_data_2029['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2029 = grouped_data_2029.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2029)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0142b-4d96-4b18-80a8-3d2691b3e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2030 = corrected_ssp126_df_2030.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2030['Average_Delay_Cost_Per_Flight'] = grouped_data_2030['sum'] / grouped_data_2030['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2030 = grouped_data_2030.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2030)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b975c2d-5f4a-4cbd-a545-c863f1ba97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2030 = corrected_ssp126_df_2030.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2030['Average_Delay_Cost_Per_Flight'] = grouped_data_2030['sum'] / grouped_data_2030['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2030 = grouped_data_2030.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2030)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eadee7d-0077-4a00-8a72-eee0342848bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [result_df_2023, result_df_2024, result_df_2025, result_df_2026, result_df_2027, result_df_2028, result_df_2029, result_df_2030]\n",
    "\n",
    "# Concatenate all DataFrames along the rows\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the mean for 'Average_Delay_Cost_Per_Flight'\n",
    "average_delay_by_carrier_SSP126 = merged_df.groupby('OP_UNIQUE_CARRIER')['Average_Delay_Cost_Per_Flight'].mean().reset_index()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(average_delay_by_carrier_SSP126)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0416e25-7b0b-405e-8ef3-fccb2defa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [result_df_2023, result_df_2024, result_df_2025, result_df_2026, result_df_2027, result_df_2028, result_df_2029, result_df_2030]\n",
    "\n",
    "# Concatenate all DataFrames along the rows\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the mean for 'Average_Delay_Cost_Per_Flight'\n",
    "average_delay_overall_SSP126 = merged_df['Average_Delay_Cost_Per_Flight'].mean()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(average_delay_overall_SSP126)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4310b-3c9d-45f4-9652-2d133b41f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cec007-140c-4d34-b5b0-1c7c368aaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2023_585 = corrected_ssp585_df_2023.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2023_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2023_585['sum'] / grouped_data_2023_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2023_585 = grouped_data_2023_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2023_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f23e1-ec31-4fe0-aa4b-ee738ccbdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2024_585 = corrected_ssp585_df_2024.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2024_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2024_585['sum'] / grouped_data_2024_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2024_585 = grouped_data_2024_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2024_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900774a-f088-4dc2-9961-71d117d938c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2025_585 = corrected_ssp585_df_2025.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2025_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2025_585['sum'] / grouped_data_2025_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2025_585 = grouped_data_2025_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2025_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d2597-4b02-45ae-af05-b7fed7938bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2026_585 = corrected_ssp585_df_2026.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2026_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2026_585['sum'] / grouped_data_2026_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2026_585 = grouped_data_2026_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2026_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73766c35-6c63-44b2-aaa4-25cbecd42ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2027_585 = corrected_ssp585_df_2027.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2027_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2027_585['sum'] / grouped_data_2027_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2027_585 = grouped_data_2027_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2027_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf59d16-43a7-4648-ba53-01c9c9a48940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2028_585 = corrected_ssp585_df_2028.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2028_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2028_585['sum'] / grouped_data_2028_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2028_585 = grouped_data_2028_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2028_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031fed20-1199-4694-b433-f2181e2a1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2029_585 = corrected_ssp585_df_2029.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2029_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2029_585['sum'] / grouped_data_2029_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2029_585 = grouped_data_2029_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2029_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703e465-fba4-461b-bdde-973cf9b7a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the sum of 'Predicted_Delay_Cost' and count of occurrences\n",
    "grouped_data_2030_585 = corrected_ssp585_df_2030.groupby('OP_UNIQUE_CARRIER')['Predicted_Delay_Cost'].agg(['sum', 'count'])\n",
    "\n",
    "# Calculate the average delay cost per flight\n",
    "grouped_data_2030_585['Average_Delay_Cost_Per_Flight'] = grouped_data_2030_585['sum'] / grouped_data_2030_585['count']\n",
    "\n",
    "# Create a new DataFrame with the result\n",
    "result_df_2030_585 = grouped_data_2030_585.reset_index()[['OP_UNIQUE_CARRIER', 'Average_Delay_Cost_Per_Flight']]\n",
    "\n",
    "# Display or use the result_df as needed\n",
    "print(result_df_2030_585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbebb8-30cc-4036-9646-da76ceb27366",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_585 = [result_df_2023_585, result_df_2024_585, result_df_2025_585, result_df_2026_585, result_df_2027_585, result_df_2028_585, result_df_2029_585, result_df_2030_585]\n",
    "\n",
    "# Concatenate all DataFrames along the rows\n",
    "merged_df_585 = pd.concat(dataframes_585, ignore_index=True)\n",
    "\n",
    "# Group by 'OP_UNIQUE_CARRIER' and calculate the mean for 'Average_Delay_Cost_Per_Flight'\n",
    "average_delay_by_carrier_SSP585 = merged_df_585.groupby('OP_UNIQUE_CARRIER')['Average_Delay_Cost_Per_Flight'].mean().reset_index()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(average_delay_by_carrier_SSP585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201246c-43a3-4bc3-a311-11b9af9cfad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_585 = [result_df_2023_585, result_df_2024_585, result_df_2025_585, result_df_2026_585, result_df_2027_585, result_df_2028_585, result_df_2029_585, result_df_2030_585]\n",
    "\n",
    "# Concatenate all DataFrames along the rows\n",
    "merged_df_585 = pd.concat(dataframes_585, ignore_index=True)\n",
    "\n",
    "# Calculate the mean for 'Average_Delay_Cost_Per_Flight' across all rows\n",
    "average_delay_overall_SSP585 = merged_df_585['Average_Delay_Cost_Per_Flight'].mean()\n",
    "\n",
    "# Print the resulting mean value\n",
    "print(\"Overall Average Delay Cost Per Flight (SSP585):\", average_delay_overall_SSP585)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf8daf-f397-474c-842c-241ee9341268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate by what percentage pices need to be increased to cover the average delay cost - SSP 5.85\n",
    "297.96 /  416.17 *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d018c-cf5d-46ec-ade1-626197b7a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate by what percentage pices need to be increased to cover the average delay cost - SSP 1.26\n",
    "304.78 / 416.17*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c6123-7ee8-4bc8-8fcb-baa39ce28865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aeca88-627d-4759-9faa-100ef5a52c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the average Delay Cost Per Flight by Carrier (SSP126)\n",
    "\n",
    "# Sort the DataFrame by 'Average_Delay_Cost_Per_Flight' in ascending order\n",
    "average_delay_by_carrier_SSP126_sorted = average_delay_by_carrier_SSP126.sort_values(by='Average_Delay_Cost_Per_Flight')\n",
    "\n",
    "# Set the color palette for the plot\n",
    "colors = sns.color_palette(\"coolwarm\", len(average_delay_by_carrier_SSP126_sorted))\n",
    "\n",
    "# Plot the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Average_Delay_Cost_Per_Flight', y='OP_UNIQUE_CARRIER', data=average_delay_by_carrier_SSP126_sorted, palette=colors)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_width():.2f}', (p.get_x() + p.get_width() / 2., p.get_y() + p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Average Delay Cost Per Flight [$]')\n",
    "plt.ylabel('Operating Carrier')\n",
    "#plt.title('Average Delay Cost Per Flight by Carrier (SSP126)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfe8e8-4817-4f81-92a5-ff484adfe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the average Delay Cost Per Flight by Carrier (SSP585)\n",
    "\n",
    "# Sort the DataFrame by 'Average_Delay_Cost_Per_Flight' in ascending order\n",
    "average_delay_by_carrier_SSP585_sorted = average_delay_by_carrier_SSP585.sort_values(by='Average_Delay_Cost_Per_Flight')\n",
    "\n",
    "# Set the color palette for the plot\n",
    "colors = sns.color_palette(\"coolwarm\", len(average_delay_by_carrier_SSP585_sorted))\n",
    "\n",
    "# Plot the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Average_Delay_Cost_Per_Flight', y='OP_UNIQUE_CARRIER', data=average_delay_by_carrier_SSP585_sorted, palette=colors)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_width():.2f}', (p.get_x() + p.get_width() / 2., p.get_y() + p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Average Delay Cost Per Flight [$]')\n",
    "plt.ylabel('Operating Carrier')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f729c3b-0f02-4134-9aa7-f72d51cade4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf6941-f72c-47fa-8420-e8b4e5fc4461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72f7cd-9e4e-4abc-9d6e-0b7ee6599b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing delay percentage of departure times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a948b-e522-4239-96d0-2a9d52e632f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2023['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2023['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_23 = corrected_ssp126_df_2023.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_23['year'] = 2023\n",
    "\n",
    "avg_delays_per_hour_126_23['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afae30-9dc1-49eb-88c9-3038e6014b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2024['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2024['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_24 = corrected_ssp126_df_2024.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_24['year'] = 2024\n",
    "\n",
    "avg_delays_per_hour_126_24['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e99ba-c55f-4d14-847a-a5f7418258d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2025['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2025['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_25 = corrected_ssp126_df_2025.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_25['year'] = 2025\n",
    "\n",
    "avg_delays_per_hour_126_25['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ebff5-2cd3-4cbc-840e-db64417b0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2026['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2026['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_26 = corrected_ssp126_df_2026.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_26['year'] = 2026\n",
    "\n",
    "avg_delays_per_hour_126_26['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ba220-eb67-4006-a2e7-7135e0b2a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2027['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2027['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_27 = corrected_ssp126_df_2027.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_27['year'] = 2027\n",
    "\n",
    "avg_delays_per_hour_126_27['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef07bbf6-0781-4026-9dd1-14f02c4631a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2028['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2028['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_28 = corrected_ssp126_df_2028.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_28['year'] = 2028\n",
    "\n",
    "avg_delays_per_hour_126_28['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37920380-020e-48b2-aa90-f7bc262949d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2029['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2029['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_29 = corrected_ssp126_df_2029.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_29['year'] = 2029\n",
    "\n",
    "avg_delays_per_hour_126_29['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe82f4-3899-407d-80d6-92c27ae5f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp126_df_2030['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp126_df_2030['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_126_30 = corrected_ssp126_df_2030.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_126_30['year'] = 2030\n",
    "\n",
    "avg_delays_per_hour_126_30['data'] = '126'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_126_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02b7c5-3169-4a8a-b7c4-f81271dbb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list containing your DataFrames\n",
    "dfs = [avg_delays_per_hour_126_23, avg_delays_per_hour_126_24, avg_delays_per_hour_126_25,\n",
    "       avg_delays_per_hour_126_26, avg_delays_per_hour_126_27, avg_delays_per_hour_126_28,\n",
    "       avg_delays_per_hour_126_29, avg_delays_per_hour_126_30]\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_concatenated = pd.concat(dfs)\n",
    "\n",
    "# Group by CRS_DEP_TIME and calculate the mean of Weather_Delayed\n",
    "result_df = df_concatenated.groupby('CRS_DEP_TIME')['Weather_Delayed'].mean().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca285f-4706-4425-82d9-f47531138eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df is the DataFrame with average Weather_Delayed values\n",
    "result_df['Weather_Delayed_percentage'] = result_df['Weather_Delayed'] * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the line and fill the area under the curve\n",
    "plt.fill_between(result_df['CRS_DEP_TIME'], result_df['Weather_Delayed_percentage'], color='skyblue', alpha=0.4)\n",
    "plt.plot(result_df['CRS_DEP_TIME'], result_df['Weather_Delayed_percentage'], linestyle='-', color='b')\n",
    "\n",
    "#plt.title('Percentage of Delayed Flights Over Time', fontdict={'fontname': 'Times New Roman', 'fontsize': 16})\n",
    "plt.xlabel('Departure Time [Hour of the Day]', fontdict={'fontname': 'Times New Roman', 'fontsize': 14})\n",
    "plt.ylabel('Percentage of Delayed Flights [%]', fontdict={'fontname': 'Times New Roman', 'fontsize': 14})\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7a723-12e9-4d1b-851a-d52afd5ef6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2023['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2023['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_23 = corrected_ssp585_df_2023.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_23['year'] = 2023\n",
    "\n",
    "avg_delays_per_hour_585_23['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848b1aa-0c2d-4c81-8c2c-89954274825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2024['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2024['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_24 = corrected_ssp585_df_2024.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_24['year'] = 2024\n",
    "\n",
    "avg_delays_per_hour_585_24['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff96049-c015-4a08-8abc-bd603e52a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2025['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2025['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_25 = corrected_ssp585_df_2025.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_25['year'] = 2025\n",
    "\n",
    "avg_delays_per_hour_585_25['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb372e-3e44-491f-b440-1d5cc6867405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2026['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2026['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_26 = corrected_ssp585_df_2026.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_26['year'] = 2026\n",
    "\n",
    "avg_delays_per_hour_585_26['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa19551-6b7f-42a0-bb0c-fb4ebfed0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2027['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2027['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_27 = corrected_ssp585_df_2027.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_27['year'] = 2027\n",
    "\n",
    "avg_delays_per_hour_585_27['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8d24d-0c4b-4b1b-bf5b-bb65a7735e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2028['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2028['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_28 = corrected_ssp585_df_2028.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_28['year'] = 2028\n",
    "\n",
    "avg_delays_per_hour_585_28['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa9051-f819-4b9d-9d0b-df8aeb758224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2029['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2029['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_29 = corrected_ssp585_df_2029.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_29['year'] = 2029\n",
    "\n",
    "avg_delays_per_hour_585_29['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7dc1bb-ac5f-4ed9-ba03-3d307e9f7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS_DEP_TIME to datetime format\n",
    "corrected_ssp585_df_2030['CRS_DEP_TIME'] = pd.to_datetime(corrected_ssp585_df_2030['CRS_DEP_TIME'], format='%H%M').dt.hour\n",
    "\n",
    "# Group by departure time and calculate average delays\n",
    "avg_delays_per_hour_585_30 = corrected_ssp585_df_2030.groupby('CRS_DEP_TIME')['Weather_Delayed', 'Predicted_Delay_Cost'].mean().reset_index()\n",
    "\n",
    "avg_delays_per_hour_585_30['year'] = 2030\n",
    "\n",
    "avg_delays_per_hour_585_30['data'] = '585'\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(avg_delays_per_hour_585_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a846e-dc1a-4080-a16d-28c97cb56ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list containing your DataFrames\n",
    "dfs = [avg_delays_per_hour_585_23, avg_delays_per_hour_585_24, avg_delays_per_hour_585_25,\n",
    "       avg_delays_per_hour_585_26, avg_delays_per_hour_585_27, avg_delays_per_hour_585_28,\n",
    "       avg_delays_per_hour_585_29, avg_delays_per_hour_585_30]\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_concatenated = pd.concat(dfs)\n",
    "\n",
    "# Group by CRS_DEP_TIME and calculate the mean of Weather_Delayed\n",
    "result_df = df_concatenated.groupby('CRS_DEP_TIME')['Weather_Delayed'].mean().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a067ba5-1177-40eb-b9cf-3d507528f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming result_df is the DataFrame with average Weather_Delayed values\n",
    "result_df['Weather_Delayed_percentage'] = result_df['Weather_Delayed'] * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the line and fill the area under the curve\n",
    "plt.fill_between(result_df['CRS_DEP_TIME'], result_df['Weather_Delayed_percentage'], color='skyblue', alpha=0.4)\n",
    "plt.plot(result_df['CRS_DEP_TIME'], result_df['Weather_Delayed_percentage'], linestyle='-', color='b')\n",
    "\n",
    "#plt.title('Percentage of Delayed Flights Over Time', fontdict={'fontname': 'Times New Roman', 'fontsize': 16})\n",
    "plt.xlabel('Departure Time [Hour of the Day]', fontdict={'fontname': 'Times New Roman', 'fontsize': 14})\n",
    "plt.ylabel('Percentage of Delayed Flights [%]', fontdict={'fontname': 'Times New Roman', 'fontsize': 14})\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad693296-b2b3-45c7-b243-3c33edc45b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9be17a-d8d7-4164-9d66-ceee0cf62755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00f0f5-d97e-4fe5-b8cf-a5e4eacf1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88011cfc-9ed7-4c03-a5f6-003233e75194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profit formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73682586-01b7-4ab9-a496-560eb54af664",
   "metadata": {},
   "source": [
    "$\\text{Profit} = \\text{Revenue} - \\text{Cost}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b8ae0-27a5-4acd-962f-c25e7c13c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of weather_delayed variable formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a8953-092f-4b39-aa57-d5460382e0e7",
   "metadata": {},
   "source": [
    "\\[ \\text{Profit} = \\text{Revenue} - \\text{Cost} \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fd75f-f7d7-4e03-b92e-53d93781b928",
   "metadata": {},
   "source": [
    "$\\text{Profit} = \\text{Selling Price} \\times \\text{Quantity Sold} - \\text{Cost}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b559ef0-b766-4cb8-9ac9-a0adc7e38575",
   "metadata": {},
   "source": [
    "\\begin{cases}\n",
    "1 & \\text{if } \\text{WEATHER_DELAY} > 0 \\text{ and/or } \\text{NAS_DELAY} > 0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895f30a-a133-4e31-9384-76d0d8b50b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
